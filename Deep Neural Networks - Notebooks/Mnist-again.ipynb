{"cells":[{"cell_type":"markdown","metadata":{"id":"84VetyCaGLyR"},"source":["<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n","\n","AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Program Operacyjny Polska Cyfrowa na lata 2014-2020\n","<hr>\n","\n","<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n","\n","<center>\n","Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego\n","Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n","Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\"\n","Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n","    </center>"]},{"cell_type":"markdown","metadata":{"id":"ziZ9i7tXbO1T"},"source":["In this lab, you will implement some of the techniques discussed in the lecture.\n","\n","Below you are given a solution to the previous scenario. Note that it has two serious drawbacks:\n"," * The output predictions do not sum up to one (i.e. it does not return a distribution) even though the images always contain exactly one digit.\n"," * It uses MSE coupled with output sigmoid which can lead to saturation and slow convergence\n","\n","**Task 1.** Use softmax instead of coordinate-wise sigmoid and use log-loss instead of MSE. Test to see if this improves convergence. Hint: When implementing backprop it might be easier to consider these two function as a single block and not even compute the gradient over the softmax values.\n","\n","**Task 2.** Implement L2 regularization and add momentum to the SGD algorithm. Play with different amounts of regularization and momentum. See if this improves accuracy/convergence.\n","\n","**Task 3 (optional).** Implement Adagrad, dropout and some simple data augmentations (e.g. tiny rotations/shifts etc.). Again, test to see how these changes improve accuracy/convergence.\n","\n","**Task 4.** Try adding extra layers to the network. Again, test how the changes you introduced affect accuracy/convergence. As a start, you can try this architecture: [784,100,30,10]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P22HqX9AbO1a"},"outputs":[],"source":["import random\n","import numpy as np\n","from torchvision import datasets, transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2136,"status":"ok","timestamp":1699356765230,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"},"user_tz":-60},"id":"N9jGPaZhbO2B","outputId":"498a4090-7e54-4a11-e332-cf9eebc927b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 77432130.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 6063758.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 22066735.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 7697183.34it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Let's read the mnist dataset\n","\n","def load_mnist(path='.'):\n","    train_set = datasets.MNIST(path, train=True, download=True)\n","    x_train = train_set.data.numpy()\n","    _y_train = train_set.targets.numpy()\n","\n","    test_set = datasets.MNIST(path, train=False, download=True)\n","    x_test = test_set.data.numpy()\n","    _y_test = test_set.targets.numpy()\n","\n","    x_train = x_train.reshape((x_train.shape[0],28*28)) / 255.\n","    x_test = x_test.reshape((x_test.shape[0],28*28)) / 255.\n","\n","    y_train = np.zeros((_y_train.shape[0], 10))\n","    y_train[np.arange(_y_train.shape[0]), _y_train] = 1\n","\n","    y_test = np.zeros((_y_test.shape[0], 10))\n","    y_test[np.arange(_y_test.shape[0]), _y_test] = 1\n","\n","    return (x_train, y_train), (x_test, y_test)\n","\n","(x_train, y_train), (x_test, y_test) = load_mnist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w3gAyqw4bO1p"},"outputs":[],"source":["def sigmoid(z):\n","    return 1.0/(1.0+np.exp(-z))\n","\n","def sigmoid_prime(z):\n","    # Derivative of the sigmoid\n","    return sigmoid(z)*(1-sigmoid(z))"]},{"cell_type":"markdown","metadata":{"id":"29Y8Wa-9q-sa"},"source":["### Task 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1699356765230,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"},"user_tz":-60},"id":"bN0ANqLGqBry","outputId":"dec9672a-bd1e-453e-d26c-f429bbb39c30"},"outputs":[{"data":{"text/plain":["array([[9.35762297e-14, 9.99999872e-01],\n","       [1.15482242e-17, 1.52299778e-08],\n","       [8.53304763e-17, 1.12535160e-07],\n","       [1.00000000e+00, 4.24835371e-18]])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["def softmax_adjusted(z):\n","  max_z = np.max(z, axis=0)\n","  return softmax(z-max_z)\n","\n","def softmax(z):\n","  return np.exp(z)/np.sum(np.exp(z), axis=0)\n","\n","z = np.array([[10, 20], [1, 2], [3, 4], [40, -20]])\n","softmax_adjusted(z)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"FgEA2XRRbO2X","outputId":"d4dbf7e9-c34a-4cf0-dd96-c2a9b603e5a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0, Accuracy: 0.8017\n","Epoch: 1, Accuracy: 0.8581\n","Epoch: 2, Accuracy: 0.8756\n","Epoch: 3, Accuracy: 0.8879\n","Epoch: 4, Accuracy: 0.8953\n","Epoch: 5, Accuracy: 0.9001\n","Epoch: 6, Accuracy: 0.907\n","Epoch: 7, Accuracy: 0.9113\n","Epoch: 8, Accuracy: 0.9149\n","Epoch: 9, Accuracy: 0.9183\n","Epoch: 10, Accuracy: 0.9213\n","Epoch: 11, Accuracy: 0.924\n","Epoch: 12, Accuracy: 0.9272\n","Epoch: 13, Accuracy: 0.9284\n","Epoch: 14, Accuracy: 0.9289\n","Epoch: 15, Accuracy: 0.9298\n","Epoch: 16, Accuracy: 0.9297\n","Epoch: 17, Accuracy: 0.931\n","Epoch: 18, Accuracy: 0.9324\n","Epoch: 19, Accuracy: 0.9332\n","Epoch: 20, Accuracy: 0.9343\n","Epoch: 21, Accuracy: 0.9351\n","Epoch: 22, Accuracy: 0.9353\n","Epoch: 23, Accuracy: 0.9357\n","Epoch: 24, Accuracy: 0.9351\n","Epoch: 25, Accuracy: 0.9364\n","Epoch: 26, Accuracy: 0.9367\n","Epoch: 27, Accuracy: 0.9369\n","Epoch: 28, Accuracy: 0.9366\n","Epoch: 29, Accuracy: 0.937\n","Epoch: 30, Accuracy: 0.9374\n","Epoch: 31, Accuracy: 0.938\n","Epoch: 32, Accuracy: 0.9382\n","Epoch: 33, Accuracy: 0.938\n","Epoch: 34, Accuracy: 0.9381\n","Epoch: 35, Accuracy: 0.938\n","Epoch: 36, Accuracy: 0.9389\n","Epoch: 37, Accuracy: 0.9386\n","Epoch: 38, Accuracy: 0.9387\n","Epoch: 39, Accuracy: 0.9388\n","Epoch: 40, Accuracy: 0.9389\n","Epoch: 41, Accuracy: 0.9393\n","Epoch: 42, Accuracy: 0.9386\n","Epoch: 43, Accuracy: 0.9387\n","Epoch: 44, Accuracy: 0.9385\n","Epoch: 45, Accuracy: 0.9387\n","Epoch: 46, Accuracy: 0.939\n","Epoch: 47, Accuracy: 0.9386\n","Epoch: 48, Accuracy: 0.9388\n","Epoch: 49, Accuracy: 0.9391\n","Epoch: 50, Accuracy: 0.9392\n","Epoch: 51, Accuracy: 0.9392\n","Epoch: 52, Accuracy: 0.9396\n","Epoch: 53, Accuracy: 0.9397\n","Epoch: 54, Accuracy: 0.9402\n","Epoch: 55, Accuracy: 0.9407\n","Epoch: 56, Accuracy: 0.9407\n","Epoch: 57, Accuracy: 0.9407\n","Epoch: 58, Accuracy: 0.9407\n","Epoch: 59, Accuracy: 0.9409\n","Epoch: 60, Accuracy: 0.941\n","Epoch: 61, Accuracy: 0.9412\n","Epoch: 62, Accuracy: 0.941\n","Epoch: 63, Accuracy: 0.9409\n","Epoch: 64, Accuracy: 0.9409\n","Epoch: 65, Accuracy: 0.9413\n","Epoch: 66, Accuracy: 0.9414\n","Epoch: 67, Accuracy: 0.9416\n","Epoch: 68, Accuracy: 0.9413\n","Epoch: 69, Accuracy: 0.941\n","Epoch: 70, Accuracy: 0.9413\n","Epoch: 71, Accuracy: 0.9414\n","Epoch: 72, Accuracy: 0.9416\n","Epoch: 73, Accuracy: 0.9413\n","Epoch: 74, Accuracy: 0.941\n","Epoch: 75, Accuracy: 0.9407\n","Epoch: 76, Accuracy: 0.9407\n","Epoch: 77, Accuracy: 0.9407\n","Epoch: 78, Accuracy: 0.9408\n","Epoch: 79, Accuracy: 0.9411\n","Epoch: 80, Accuracy: 0.941\n","Epoch: 81, Accuracy: 0.9408\n","Epoch: 82, Accuracy: 0.9412\n","Epoch: 83, Accuracy: 0.9412\n","Epoch: 84, Accuracy: 0.9414\n","Epoch: 85, Accuracy: 0.9414\n","Epoch: 86, Accuracy: 0.9415\n","Epoch: 87, Accuracy: 0.9413\n","Epoch: 88, Accuracy: 0.9413\n","Epoch: 89, Accuracy: 0.9413\n","Epoch: 90, Accuracy: 0.9414\n","Epoch: 91, Accuracy: 0.9413\n","Epoch: 92, Accuracy: 0.9413\n","Epoch: 93, Accuracy: 0.9416\n","Epoch: 94, Accuracy: 0.9417\n","Epoch: 95, Accuracy: 0.9418\n","Epoch: 96, Accuracy: 0.9416\n","Epoch: 97, Accuracy: 0.9416\n","Epoch: 98, Accuracy: 0.9414\n","Epoch: 99, Accuracy: 0.9408\n"]}],"source":["class Network(object):\n","    def __init__(self, sizes):\n","        # initialize biases and weights with random normal distr.\n","        # weights are indexed by target node first\n","        self.num_layers = len(sizes)\n","        self.sizes = sizes\n","        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n","        self.weights = [np.random.randn(y, x)\n","                        for x, y in zip(sizes[:-1], sizes[1:])]\n","\n","        self.debug=False\n","\n","    def feedforward(self, a):\n","        # Run the network on a batch\n","        a = a.T\n","        for b, w in zip(self.biases, self.weights):\n","            a = sigmoid(np.matmul(w, a)+b)\n","        return a\n","\n","    def update_mini_batch(self, mini_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch which is as in tensorflow API.\n","        # eta is the learning rate\n","        nabla_b, nabla_w = self.backprop(mini_batch[0].T,mini_batch[1].T)\n","\n","        self.weights = [w-(eta/len(mini_batch[0]))*nw\n","                        for w, nw in zip(self.weights, nabla_w)]\n","        self.biases = [b-(eta/len(mini_batch[0]))*nb\n","                       for b, nb in zip(self.biases, nabla_b)]\n","\n","    def backprop(self, x, y):\n","        # For a single input (x,y) return a pair of lists.\n","        # First contains gradients over biases, second over weights.\n","        if self.debug:\n","          print(x.shape, y.shape)\n","        g = x\n","        gs = [g] # list to store all the gs, layer by layer\n","        fs = [] # list to store all the fs, layer by layer\n","        for b, w in zip(self.biases, self.weights):\n","            f = np.dot(w, g)+b\n","            fs.append(f)\n","            g = sigmoid(f)\n","            gs.append(g)\n","\n","        gs[-1] = softmax_adjusted(fs[-1])\n","        if self.debug:\n","          print(gs[-1].shape)\n","\n","        # backward pass <- both steps at once\n","        dLdg = self.cost_derivative(gs[-1], y)\n","\n","        if self.debug:\n","          print(dLdg.shape)\n","\n","        dLdfs = []\n","        for w,g in reversed(list(zip(self.weights,gs[1:]))):\n","            if self.debug:\n","              print(w.shape)\n","            dLdf = np.multiply(dLdg,np.multiply(g,1-g))\n","            dLdfs.append(dLdf)\n","            dLdg = np.matmul(w.T, dLdf)\n","\n","        # return None\n","\n","        dLdWs = [np.matmul(dLdf,g.T) for dLdf,g in zip(reversed(dLdfs),gs[:-1])]\n","        dLdBs = [np.sum(dLdf,axis=1).reshape(dLdf.shape[0],1) for dLdf in reversed(dLdfs)]\n","        return (dLdBs,dLdWs)\n","\n","    def evaluate(self, test_data):\n","        # Count the number of correct answers for test_data\n","        pred = np.argmax(self.feedforward(test_data[0]),axis=0)\n","        corr = np.argmax(test_data[1],axis=1).T\n","        return np.mean(pred==corr)\n","\n","    def cost_derivative(self, output_activations, y):\n","        return output_activations-y\n","\n","    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n","        x_train, y_train = training_data\n","        if test_data:\n","            x_test, y_test = test_data\n","        for j in range(epochs):\n","            for i in range(x_train.shape[0] // mini_batch_size):\n","                x_mini_batch = x_train[(mini_batch_size*i):(mini_batch_size*(i+1))]\n","                y_mini_batch = y_train[(mini_batch_size*i):(mini_batch_size*(i+1))]\n","                self.update_mini_batch((x_mini_batch, y_mini_batch), eta)\n","            if test_data:\n","                print(\"Epoch: {0}, Accuracy: {1}\".format(j, self.evaluate((x_test, y_test))))\n","            else:\n","                print(\"Epoch: {0}\".format(j))\n","\n","\n","network = Network([784,30,10])\n","network.SGD((x_train, y_train), epochs=100, mini_batch_size=100, eta=3.0, test_data=(x_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"BKBj9u_cX6-O"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/mim-uw/dnn-2023-24/blob/master/docs/DNN-Lab-3-mnist-again-student.ipynb","timestamp":1698659239394},{"file_id":"1mbRybTuEd5hfMgPq47jAy40aizNX03x8","timestamp":1665425459792},{"file_id":"1hs2ViNkY7vFE7l_PL7b-2XIN17cxbsyL","timestamp":1635823858600},{"file_id":"1t76la2tUWVLnEK7IKxdFZn_Y0be3xZud","timestamp":1635823610862}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":0}