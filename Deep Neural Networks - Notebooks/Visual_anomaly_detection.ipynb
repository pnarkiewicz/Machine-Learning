{"cells":[{"cell_type":"markdown","metadata":{"id":"BSoPLksd1D3S"},"source":["# Low-shot visual anomaly detection\n","\n","In this notebook you'll investigate visual anomaly detection in a typical industrial setting - we don't have much data and we can train only only normal (non-anomalous) examples.\n","Read the [PADIM paper](https://arxiv.org/pdf/2011.08785.pdf) carefully.\n","The code here is based on the original implementation from its authors.\n","\n","If you have any questions - please write them on slack in the channel.\n","\n","### Bibliography\n","\n","1. Defard, T., Setkov, A., Loesch, A., & Audigier, R. (2021). [Padim: a patch distribution modeling framework for anomaly detection and localization](https://arxiv.org/pdf/2011.08785.pdf). In International Conference on Pattern Recognition (pp. 475-489). Cham: Springer International Publishing."]},{"cell_type":"markdown","metadata":{"id":"C-yA9Cqk1D3U"},"source":["## Data\n","\n","In case of any problems - please visit [MVTec AD](https://www.mvtec.com/company/research/datasets/mvtec-ad/downloads) to get the access to the data."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"XQm8QlAw1D3U","executionInfo":{"status":"ok","timestamp":1702731052022,"user_tz":-60,"elapsed":12117,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[],"source":["# %pip install --quiet gdown  # for those who don't run it on Google Colab\n","!gdown -q '1r7WJeDb-E5zzgQSOx7F7bNWg8kYX3yKE'\n","!gdown -q '1Kb420ygkN1iBni5Iy_-psLGNoY0gQFk9'\n","!gdown -q '12wDP9I3aVIr1qLekWY3GLhQO7c6SRhGn'"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"5jydSW_-1D3V","executionInfo":{"status":"ok","timestamp":1702731060098,"user_tz":-60,"elapsed":8086,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[],"source":["from pathlib import Path\n","import tarfile\n","\n","DATA_PATH = Path('./mvtec_anomaly_detection')\n","DATA_PATH.mkdir(exist_ok=True)\n","\n","for class_name in ['bottle', 'metal_nut', 'transistor']:\n","    if not (DATA_PATH / class_name).exists():\n","        with tarfile.open(class_name + '.tar.xz') as tar:\n","            tar.extractall(path=DATA_PATH)"]},{"cell_type":"markdown","metadata":{"id":"_ay_UZJY1D3V"},"source":["## PADIM implementation"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"09E0Av5x1D3V","executionInfo":{"status":"ok","timestamp":1702731066758,"user_tz":-60,"elapsed":6681,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[],"source":["import os\n","import random\n","import time\n","from pathlib import Path\n","from random import sample\n","from typing import cast, Any, Dict, List, Optional, Tuple, Union\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.backends, torch.backends.mps\n","import torch.nn.functional as F\n","from numpy.typing import NDArray\n","from matplotlib import colors\n","from PIL import Image\n","from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n","from scipy.spatial.distance import mahalanobis\n","from scipy.ndimage import gaussian_filter\n","from skimage import morphology\n","from skimage.segmentation import mark_boundaries\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.models import wide_resnet50_2, resnet18, Wide_ResNet50_2_Weights, ResNet18_Weights\n","from torch import nn\n","from torchvision import transforms as T\n","from tqdm import tqdm\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","FloatNDArray = NDArray[np.float32]"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"APdJil-C1D3W","executionInfo":{"status":"ok","timestamp":1702731066758,"user_tz":-60,"elapsed":28,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[],"source":["# Leave it as is if you're unsure, this notebook will guess this for you below.\n","DEVICE: Optional[torch.device] = None\n","SEED: int = 42  # do not modify\n","\n","plt.style.use(\"dark_background\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"elPvkn4J1D3W","executionInfo":{"status":"ok","timestamp":1702731066758,"user_tz":-60,"elapsed":27,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[],"source":["def seed_all(seed: int = 0) -> None:\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","\n","\n","def get_best_device_for_pytorch() -> torch.device:\n","    if torch.cuda.is_available():\n","        device_str = \"cuda\"     # GPU\n","    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n","        device_str = \"mps\"      # Apple silicon\n","    else:\n","        device_str = \"cpu\"      # CPU\n","    return torch.device(device_str)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"XhQvK43r1D3W","outputId":"1daf2570-ddb7-41e1-af28-975845003bc8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702731066758,"user_tz":-60,"elapsed":27,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using PyTorch with cuda backend.\n","Seeded everything with 42.\n"]}],"source":["if not DEVICE:\n","    DEVICE = get_best_device_for_pytorch()\n","print(f\"Using PyTorch with {DEVICE} backend.\")\n","\n","seed_all(SEED)\n","print(f\"Seeded everything with {SEED}.\")"]},{"cell_type":"markdown","metadata":{"id":"3EEBZmGt1D3X"},"source":["### MVTecDataset"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Jz6MuQ1i1D3X","executionInfo":{"status":"ok","timestamp":1702731066758,"user_tz":-60,"elapsed":7,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[],"source":["class MVTecDataset(Dataset[Tuple[torch.Tensor, int, torch.Tensor]]):\n","    \"\"\"MVTec dataset of industrial objects with and without anomalies.\n","\n","    Yields (x, y, mask) tuples where:\n","    - x is an RGB image from the class, as float tensor of shape (3, cropsize, cropsize);\n","    - y is an int, 0 for good images, 1 for anomalous images;\n","    - mask is 0 for normal pixels, 1 for anomalous pixels, as float tensor of shape (1, cropsize, cropsize).\n","\n","    Source: https://github.com/xiahaifeng1995/PaDiM-Anomaly-Detection-Localization-master/blob/main/datasets/mvtec.py\n","    \"\"\"\n","\n","    def __init__(self, dataset_path: Path, class_name: str = 'bottle',\n","                 is_train: bool = True, resize: int = 256, cropsize: int = 224, return_only_indices=False):\n","        self.dataset_path = dataset_path\n","        self.class_name = class_name\n","        assert (dataset_path / class_name).is_dir(), f'Dataset class not found: {dataset_path / class_name}'\n","        self.is_train = is_train\n","\n","        self.resize = resize\n","        self.cropsize = cropsize\n","\n","        # load dataset\n","        self.x, self.y, self.mask = self.load_dataset_folder()\n","\n","        # set transforms\n","        self.transform_x = T.Compose([T.Resize(resize, Image.LANCZOS),\n","                                      T.CenterCrop(cropsize),\n","                                      T.ToTensor(),\n","                                      T.Normalize(mean=[0.485, 0.456, 0.406],\n","                                                  std=[0.229, 0.224, 0.225])])\n","        self.transform_mask = T.Compose([T.Resize(resize, Image.NEAREST),\n","                                         T.CenterCrop(cropsize),\n","                                         T.ToTensor()])\n","\n","        self.return_only_indices = return_only_indices\n","\n","    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int, torch.Tensor]:\n","        if self.return_only_indices:  # Used for checking the answer of T1.1.\n","            return idx\n","\n","        x, y, mask = self.x[idx], self.y[idx], self.mask[idx]\n","\n","        x = Image.open(x).convert('RGB')\n","        x = cast(torch.Tensor, self.transform_x(x))\n","\n","        if y == 0:\n","            mask = torch.zeros([1, self.cropsize, self.cropsize])\n","        else:\n","            assert mask is not None\n","            mask = Image.open(mask)\n","            mask = cast(torch.Tensor, self.transform_mask(mask))\n","\n","        return x, y, mask\n","\n","    def __len__(self) -> int:\n","        return len(self.x)\n","\n","    def load_dataset_folder(self) -> Tuple[List[Path], List[int], List[Optional[Path]]]:\n","        phase = 'train' if self.is_train else 'test'\n","        x: List[Path] = []\n","        y: List[int] = []\n","        mask: List[Optional[Path]] = []\n","\n","        img_dir = self.dataset_path / self.class_name / phase\n","        gt_dir = self.dataset_path / self.class_name / 'ground_truth'\n","\n","        for img_type_dir in sorted(img_dir.iterdir()):\n","            # Load images.\n","            if not img_type_dir.is_dir():\n","                continue\n","            img_fpath_list = sorted(img_type_dir.glob('*.png'))\n","            x.extend(img_fpath_list)\n","\n","            # Load ground-truth labels and masks.\n","            if img_type_dir.name == 'good':\n","                y.extend([0] * len(img_fpath_list))\n","                mask.extend([None] * len(img_fpath_list))\n","            else:\n","                y.extend([1] * len(img_fpath_list))\n","                mask.extend([gt_dir / img_type_dir.name / (f.stem + '_mask.png')\n","                            for f in img_fpath_list])\n","\n","        assert len(x) == len(y) == len(mask), 'Number of x, y, and mask should be the same.'\n","        return x, y, mask"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"TeFUMA2t1D3X","executionInfo":{"status":"ok","timestamp":1702731066759,"user_tz":-60,"elapsed":7,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[],"source":["def sample_idx(number_of_features: int, max_number_of_features: int) -> torch.Tensor:\n","    assert number_of_features <= max_number_of_features\n","    return torch.tensor(sample(range(0, max_number_of_features), number_of_features))\n","\n","\n","def denormalization(x: FloatNDArray) -> NDArray[np.uint8]:\n","    \"\"\"Denormalize with ImageNet values.\"\"\"\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    return (((x.transpose(1, 2, 0) * std) + mean) * 255.).astype(np.uint8)\n","\n","\n","def embedding_concat(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n","    \"\"\"\n","    Concatenate embeddings (along the channel dimension, upscaling y to match x).\n","\n","    Args:\n","        x: Tensor of shape (B, C1, H1, W1).\n","        y: Tensor of shape (B, C2, H2, W2).\n","\n","    Returns:\n","        Tensor of shape is (B, C1 + C2, H1, W1).\n","    \"\"\"\n","    B, C1, H1, W1 = x.size()\n","    _, C2, H2, W2 = y.size()\n","    s = int(H1 / H2)\n","    x = F.unfold(x, kernel_size=s, dilation=1, stride=s)\n","    x = x.view(B, C1, s * s, H2, W2)\n","    z = torch.zeros(B, C1 + C2, s * s, H2, W2).to(x.device)\n","    for i in range(s * s):\n","        z[:, :, i, :, :] = torch.cat((x[:, :, i, :, :], y), dim=1)\n","    z = z.view(B, -1, H2 * W2)\n","    z = F.fold(z, kernel_size=s, output_size=(H1, W1), stride=s)\n","    return z\n","\n","def concatenate_embeddings_from_all_layers(layer_outputs: Dict[str, torch.Tensor]) -> torch.Tensor:\n","        embedding_vectors = layer_outputs['layer1']\n","        for layer_name in ['layer2', 'layer3']:\n","            embedding_vectors = embedding_concat(embedding_vectors, layer_outputs[layer_name])\n","        return embedding_vectors\n","\n","def plot_fig(test_img, scores, gts, threshold: float, save_dir: Path, class_name: str):\n","    num = len(scores)\n","    vmax = scores.max() * 255.\n","    vmin = scores.min() * 255.\n","    for i in range(num):\n","        img = test_img[i]\n","        img = denormalization(img)\n","        gt = gts[i].transpose(1, 2, 0).squeeze()\n","        heat_map = scores[i] * 255\n","        mask = scores[i]\n","        mask[mask > threshold] = 1\n","        mask[mask <= threshold] = 0\n","        kernel = morphology.disk(4)\n","        mask = morphology.opening(mask, kernel)\n","        mask *= 255\n","        vis_img = mark_boundaries(img, mask, color=(1, 0, 0), mode='thick')\n","        fig_img, ax_img = plt.subplots(1, 5, figsize=(12, 3))\n","        fig_img.subplots_adjust(right=0.9)\n","        norm = colors.Normalize(vmin=vmin, vmax=vmax)\n","        for ax_i in ax_img:\n","            ax_i.axes.xaxis.set_visible(False)\n","            ax_i.axes.yaxis.set_visible(False)\n","        ax_img[0].imshow(img)\n","        ax_img[0].title.set_text('Image')\n","        ax_img[1].imshow(gt, cmap='gray')\n","        ax_img[1].title.set_text('GroundTruth')\n","        ax = ax_img[2].imshow(heat_map, cmap='jet', norm=norm)\n","        ax_img[2].imshow(img, cmap='gray', interpolation='none')\n","        ax_img[2].imshow(heat_map, cmap='jet', alpha=0.5, interpolation='none')\n","        ax_img[2].title.set_text('Predicted heat map')\n","        ax_img[3].imshow(mask, cmap='gray')\n","        ax_img[3].title.set_text('Predicted mask')\n","        ax_img[4].imshow(vis_img)\n","        ax_img[4].title.set_text('Segmentation result')\n","        left = 0.92\n","        bottom = 0.15\n","        width = 0.015\n","        height = 1 - 2 * bottom\n","        rect = [left, bottom, width, height]\n","        cbar_ax = fig_img.add_axes(rect)\n","        cb = plt.colorbar(ax, shrink=0.6, cax=cbar_ax, fraction=0.046)\n","        cb.ax.tick_params(labelsize=8)\n","        font = {\n","            'family': 'serif',\n","            'color': 'black',\n","            'weight': 'normal',\n","            'size': 8,\n","        }\n","        cb.set_label('Anomaly Score', fontdict=font)\n","\n","        fig_img.savefig(save_dir / f'{class_name}_{i}', dpi=100)\n","        plt.close()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"khzq9iU41D3X","executionInfo":{"status":"ok","timestamp":1702731066759,"user_tz":-60,"elapsed":7,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[],"source":["def get_feature_extractor(arch: str) -> nn.Module:\n","    if arch == 'resnet18':\n","        model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1, progress=True)\n","        # t_d = 448\n","        # d = 40\n","    elif arch == 'wide_resnet50_2':\n","        model = wide_resnet50_2(weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1, progress=True)\n","        # t_d = 1792\n","        # d = 550\n","    else:\n","        raise NotImplementedError\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"IGNitdYl1D3X"},"source":["### PADIM class"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"81q8JY4s1D3X","executionInfo":{"status":"ok","timestamp":1702731066759,"user_tz":-60,"elapsed":7,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[],"source":["class PADIM():\n","\n","    def __init__(\n","            self,\n","            backbone: str,\n","            device: torch.device,\n","            save_path: Path,\n","            backbone_features_idx: torch.Tensor,\n","            class_names: List[str] = [\"bottle\"],\n","            plot_metrics: bool = False,\n","    ) -> None:\n","        self.arch = backbone\n","        self.device = device\n","        self.model = get_feature_extractor(backbone)\n","        self.model.to(device)\n","        self.model.eval()\n","\n","        self.feature_subset_indices = backbone_features_idx\n","        self.feature_subset_indices.to(device)\n","\n","        self.outputs: Dict[str, torch.Tensor] = {}\n","\n","        self.class_names = class_names\n","        self.save_path = save_path\n","        self.plot_metrics = plot_metrics\n","\n","        self.setup_hooks()\n","        (self.save_path / f'temp_{self.arch}').mkdir(parents=True, exist_ok=True)\n","\n","        self.mean: FloatNDArray  # shape (C, H * W)\n","        self.cov: FloatNDArray  # shape (C, C, H * W)\n","\n","    def setup_hooks(self):\n","        \"\"\"Setup hooks to store model's intermediate outputs.\"\"\"\n","        self.model.layer1[-1].register_forward_hook(lambda _, __, x: self.outputs.update({'layer1': x}))\n","        self.model.layer2[-1].register_forward_hook(lambda _, __, x: self.outputs.update({'layer2': x}))\n","        self.model.layer3[-1].register_forward_hook(lambda _, __, x: self.outputs.update({'layer3': x}))\n","\n","    def train_and_test(self, train_dataloader: DataLoader, test_dataloader: DataLoader) -> float:\n","        self.train(train_dataloader)\n","        return self.test(test_dataloader)\n","\n","    def train(self, train_dataloader: DataLoader) -> None:\n","        self.train_outputs: Dict[str, List[torch.Tensor]] = {'layer1': [], 'layer2': [], 'layer3': []}\n","        for x, _, _ in tqdm(train_dataloader, desc='Feature extraction (train)'):\n","            # Run model prediction.\n","            with torch.no_grad():\n","                _ = self.model(x.to(DEVICE))\n","            # Get intermediate layer outputs.\n","            assert list(self.outputs.keys())  == ['layer1', 'layer2', 'layer3'], list(self.outputs.keys())\n","            for k, v in self.outputs.items():\n","                self.train_outputs[k].append(v.cpu().detach())\n","            # Reset hook outputs.\n","            self.outputs = {}\n","\n","        embedding_vectors = concatenate_embeddings_from_all_layers(\n","            {k: torch.cat(v, 0) for k, v in self.train_outputs.items()})\n","        embedding_vectors_subset = torch.index_select(embedding_vectors, 1, self.feature_subset_indices.cpu())\n","\n","        self.mean, self.cov = self.estimate_multivariate_gaussian(embedding_vectors_subset)\n","        del(self.train_outputs)\n","\n","    def estimate_multivariate_gaussian(self, embedding_vectors: torch.Tensor\n","                                       ) -> Tuple[FloatNDArray, FloatNDArray]:\n","        \"\"\"Calculates multivariate Gaussian distribution.\n","\n","        Takes embeddings of shape (N, C, H, W).\n","        Returns (mean, covariance) of shape (C, H * W) and (C, C, H * W) respectively.\n","        \"\"\"\n","        B, C, H, W = embedding_vectors.size()\n","        embedding_vectors = embedding_vectors.view(B, C, H * W)\n","        mean = torch.mean(embedding_vectors, dim=0).numpy()\n","        cov = torch.zeros(C, C, H * W).numpy()\n","        I = np.identity(C)\n","        for i in tqdm(range(H * W), desc=\"Covariance estimation\"):\n","            cov[:, :, i] = np.cov(embedding_vectors[:, :, i].numpy(), rowvar=False) + 0.01 * I\n","        return mean, cov\n","\n","    def test(self, test_dataloader: DataLoader) -> float:\n","        self.test_outputs: Dict[str, List[torch.Tensor]] = {'layer1': [], 'layer2': [], 'layer3': []}\n","        test_imgs: List[FloatNDArray] = []\n","        gt_list: List[NDArray[Any]] = []\n","        gt_mask_list: List[FloatNDArray] = []\n","\n","        # Extract test set features.\n","        for x, y, mask in tqdm(test_dataloader, desc='Feature extraction (test)', disable=False):\n","            x_shape = x.shape\n","            test_imgs.extend(x.cpu().detach().numpy())\n","            gt_list.extend(y.cpu().detach().numpy())\n","            gt_mask_list.extend(mask.cpu().detach().numpy())\n","            # Run model prediction.\n","            with torch.no_grad():\n","                _ = self.model(x.to(DEVICE))\n","            # Get intermediate layer outputs.\n","            assert list(self.outputs.keys())  == ['layer1', 'layer2', 'layer3']\n","            for k, v in self.outputs.items():\n","                self.test_outputs[k].append(v.cpu().detach())\n","            # Reset hook outputs.\n","            self.outputs = {}\n","        gt_mask = np.asarray(gt_mask_list)  # shape (len(test_dataset), 1, H, W)\n","\n","        embedding_vectors = concatenate_embeddings_from_all_layers(\n","            {k: torch.cat(v, 0) for k, v in self.test_outputs.items()})\n","        embedding_vectors_subset = torch.index_select(embedding_vectors, 1, self.feature_subset_indices.cpu())\n","\n","        distances = self.calculate_distances(embedding_vectors_subset)\n","        score_map = self.prepare_anomaly_map((x_shape[2], x_shape[3]), distances)\n","\n","        img_fpr, img_tpr, img_auroc = self.calculate_auroc_image_level(score_map, gt_list)\n","        pxl_fpr, pxl_tpr, pxl_auroc = self.calculate_auroc_pixel_level(score_map, gt_mask)\n","\n","        if self.plot_metrics:\n","            print(f'[TEST] Image AUROC: {img_auroc:.3f}')\n","            print(f'[TEST] Pixel AUROC: {pxl_auroc:.3f}')\n","            threshold = self.calculate_optimal_threshold(score_map, gt_mask)\n","            self.plot_test_results_for_class(gt_mask_list, test_imgs, score_map, threshold, img_fpr, img_tpr, img_auroc, pxl_fpr, pxl_tpr, pxl_auroc)\n","\n","        return pxl_auroc\n","\n","    # TODO: Some of your code for Task 1 goes here. You can add more functions if needed, but use the ones below - we will use them for checking your solution.\n","    def test_permutation_importance(self, val_dataloader: DataLoader, features_to_permute: List[int]) -> List[float]:\n","        \"\"\"Runs a series of tests on `val_dataloader`.\n","        Returns a list of pixelwise AUROCs, where the n-th element of the list is generated by testing the embeddings from `permute_feature(embeddings, n).\"\"\"\n","        pxl_aurocs = []\n","        embedding_vectors_subset, gt_mask, x_shape = self.get_gt_mask_embeddings_input_shape(val_dataloader)\n","\n","        for feature_to_permute in features_to_permute:\n","          embedding_vectors_subset_permuted = self.permute_feature(embedding_vectors_subset, feature_to_permute)\n","          pxl_auroc = self.get_score(embedding_vectors_subset_permuted, x_shape, gt_mask)\n","          pxl_aurocs.append(pxl_auroc)\n","\n","        return pxl_aurocs\n","\n","    def permute_feature(self, embedding_vectors_subset: torch.Tensor, number_of_feature_to_permute: int) -> torch.Tensor:\n","        \"\"\"Permutes the embeddings.\n","\n","        Takes embeddings of shape (N, C, H, W) and feature number to permute.\n","        Returns embeddings with the same shape. See the description of T1 for the details.\n","        \"\"\"\n","        N, _, H, W = embedding_vectors_subset.size()\n","        embedding_vectors_subset_copy = embedding_vectors_subset.clone()\n","        for n in range(N):\n","          embedding_vectors_subset_copy[n, number_of_feature_to_permute, :, :] =  embedding_vectors_subset_copy[n, number_of_feature_to_permute, :, :].reshape(-1)[torch.randperm(H*W)].reshape((H, W))\n","        return embedding_vectors_subset_copy\n","\n","    def get_gt_mask_embeddings_input_shape(self, val_dataloader):\n","        \"\"\"Return raw embeddings subset, gt mask and input shape for val_dataloader\n","        \"\"\"\n","        self.val_outputs: Dict[str, List[torch.Tensor]] = {'layer1': [], 'layer2': [], 'layer3': []}\n","        gt_mask_list: List[FloatNDArray] = []\n","\n","        for x, y, mask in tqdm(val_dataloader, desc='Feature extraction (val)', disable=False):\n","            x_shape = x.shape\n","            gt_mask_list.extend(mask.cpu().detach().numpy())\n","            # Run model prediction.\n","            with torch.no_grad():\n","                _ = self.model(x.to(DEVICE))\n","            # Get intermediate layer outputs.\n","            assert list(self.outputs.keys())  == ['layer1', 'layer2', 'layer3']\n","            for k, v in self.outputs.items():\n","                self.val_outputs[k].append(v.cpu().detach())\n","            # Reset hook outputs.\n","            self.outputs = {}\n","        gt_mask = np.asarray(gt_mask_list)  # shape (len(test_dataset), 1, H, W)\n","        embedding_vectors = concatenate_embeddings_from_all_layers(\n","            {k: torch.cat(v, 0) for k, v in self.val_outputs.items()})\n","        embedding_vectors_subset = torch.index_select(embedding_vectors, 1, self.feature_subset_indices.cpu())\n","        return embedding_vectors_subset, gt_mask, x_shape\n","\n","    def get_score(self, embedding_vectors_subset, x_shape, gt_mask):\n","        \"\"\"Given embeddings, input shape, gt_mask return pixel auroc score\n","        \"\"\"\n","        distances = self.calculate_distances(embedding_vectors_subset)\n","        score_map = self.prepare_anomaly_map((x_shape[2], x_shape[3]), distances)\n","        _, _, pxl_auroc = self.calculate_auroc_pixel_level(score_map, gt_mask)\n","        return pxl_auroc\n","    # TODO: End of your code for Task 1 (here)\n","\n","    def plot_test_results_for_class(self, gt_mask_list, test_imgs,\n","                                    score_map, threshold: float,\n","                                    img_fpr, img_tpr, img_auroc: float,\n","                                    pxl_fpr, pxl_tpr, pxl_auroc: float):\n","        _, ax = plt.subplots(1, 2, figsize=(8, 4))\n","        ax[0].plot(img_fpr, img_tpr, label=f'Image AUROC: {img_auroc:.3f}')\n","        ax[1].plot(pxl_fpr, pxl_tpr, label=f'Pixel AUROC: {pxl_auroc:.3f}')\n","\n","        save_dir = self.save_path / f'pictures_{self.arch}'\n","        save_dir.mkdir(parents=True, exist_ok=True)\n","        plot_fig(test_imgs, score_map, gt_mask_list,\n","                 threshold, save_dir, \"\")\n","\n","    def calculate_auroc_image_level(self, score_map: FloatNDArray, gt_list: List[NDArray[Any]]) -> Tuple[FloatNDArray, FloatNDArray, float]:\n","        \"\"\"Calculate image-level AUROC score.\"\"\"\n","        img_scores = score_map.reshape(score_map.shape[0], -1).max(axis=1)\n","        fpr, tpr, _ = roc_curve(gt_list, img_scores)  # false-positive-rates and true-positive-rates for consecutive thresholds (for plotting).\n","        img_auroc = roc_auc_score(gt_list, img_scores)\n","        return fpr, tpr, float(img_auroc)\n","\n","    def calculate_auroc_pixel_level(self, score_map: FloatNDArray, gt_mask: FloatNDArray) -> Tuple[FloatNDArray, FloatNDArray, float]:\n","        \"\"\"Calculate per-pixel level AUROC.\"\"\"\n","        assert score_map.shape == gt_mask.squeeze().shape, f\"{score_map.shape=}, {gt_mask.shape=}\"\n","        fpr, tpr, _ = roc_curve(gt_mask.flatten(), score_map.flatten())\n","        per_pixel_auroc = roc_auc_score(gt_mask.flatten(), score_map.flatten())\n","        return fpr, tpr, float(per_pixel_auroc)\n","\n","    def calculate_optimal_threshold(self, score_map: FloatNDArray, gt_mask: FloatNDArray) -> float:\n","        \"\"\"Calculate the optimal threshold with regard to F1 score.\"\"\"\n","        assert score_map.shape == gt_mask.squeeze().shape\n","        precision, recall, thresholds = precision_recall_curve(\n","            gt_mask.flatten(), score_map.flatten())\n","        a = 2 * precision * recall\n","        b = precision + recall\n","        f1 = np.divide(a, b, out=np.zeros_like(a), where=(b != 0))\n","        threshold = thresholds[np.argmax(f1)]\n","        return threshold\n","\n","    def calculate_distances(self, embedding_vectors: torch.Tensor) -> FloatNDArray:\n","        \"\"\"Calculate Mahalanobis distance of each embedding vector from self.mean.\n","\n","        For embeddings of shape (N, C, H, W), returns shape (N, H, W).\n","        \"\"\"\n","        B, C, H, W = embedding_vectors.size()\n","        embedding_vectors = embedding_vectors.view(B, C, H * W).numpy()\n","        dist_list: List[List[np.float64]] = []\n","        for i in range(H * W):\n","            mean = self.mean[:, i]\n","            conv_inv = np.linalg.inv(self.cov[:, :, i])\n","            dist = [mahalanobis(sample[:, i], mean, conv_inv)\n","                    for sample in embedding_vectors]\n","            dist_list.append(dist)\n","\n","        return np.array(dist_list).transpose(1, 0).reshape(B, H, W)\n","\n","    def prepare_anomaly_map(self, shape: Tuple[int, int], distances: FloatNDArray) -> FloatNDArray:\n","        \"\"\"Upsample distances to `shape`, apply Gaussian smoothing, and normalize to [0,1].\n","\n","        For distances of shape (N, H, W) and `shape` equal to (H2, W2), returns shape (N, H2, W2).\n","        \"\"\"\n","        dists = torch.Tensor(distances).unsqueeze(1)\n","        shape = (dists.shape[0],) + shape\n","        score_map = cast(FloatNDArray, F.interpolate(\n","            dists, size=shape[2], mode='bilinear', align_corners=False).squeeze().numpy())\n","        for i in range(score_map.shape[0]):\n","            score_map[i] = gaussian_filter(score_map[i], sigma=4)\n","\n","        min_score, max_score = score_map.min(), score_map.max()\n","        return (score_map - min_score) / (max_score - min_score + 1e-10)"]},{"cell_type":"markdown","metadata":{"id":"Y1r38unE1D3Y"},"source":["### Let's see whether it works.\n","Take a look to the `SAVE_PATH` to inspect the results."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"wwljmYDM1D3Y","outputId":"a5e7cc52-292f-43a8-f05d-26352a1fa0d5","colab":{"base_uri":"https://localhost:8080/","height":511},"executionInfo":{"status":"ok","timestamp":1702731126768,"user_tz":-60,"elapsed":60016,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["========== bottle\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 185MB/s]\n","Feature extraction (train): 100%|██████████| 105/105 [00:10<00:00, 10.01it/s]\n","Covariance estimation: 100%|██████████| 3136/3136 [00:01<00:00, 2521.86it/s]\n","Feature extraction (test): 100%|██████████| 42/42 [00:03<00:00, 11.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[TEST] Image AUROC: 0.998\n","[TEST] Pixel AUROC: 0.981\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 800x400 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["seed_all(SEED)\n","CLASS_NAMES = [\n","            'bottle', #'metal_nut'\n","            # 'cable', 'capsule', 'carpet', 'grid', 'hazelnut', 'leather',\n","            # 'pill', 'screw', 'tile', 'toothbrush', 'transistor', 'wood', 'zipper'\n","        ]\n","BATCH_SIZE = 2\n","RESIZE = 256 * 1\n","CROP_SIZE = 224 * 1\n","BACKBONE = \"resnet18\"\n","NUMBER_OF_BACKBONE_FEATURES = 50\n","MAX_NUMBER_OF_BACKBONE_FEATURES = 448\n","\n","run_timestamp = time.time()\n","for class_name in CLASS_NAMES:\n","    print('=' * 10, class_name)\n","    SAVE_PATH = Path(f\"./results/{run_timestamp}/{class_name}\")\n","\n","    train_dataset = MVTecDataset(DATA_PATH, class_name=class_name, is_train=True, resize=RESIZE, cropsize=CROP_SIZE)\n","    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n","    test_dataset = MVTecDataset(DATA_PATH, class_name=class_name, is_train=False, resize=RESIZE, cropsize=CROP_SIZE)\n","    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n","\n","    padim = PADIM(\n","        backbone=BACKBONE,\n","        device=DEVICE,\n","        backbone_features_idx=sample_idx(NUMBER_OF_BACKBONE_FEATURES, MAX_NUMBER_OF_BACKBONE_FEATURES),\n","        save_path=SAVE_PATH,\n","        plot_metrics=True,\n","    )\n","\n","    padim.train_and_test(\n","        train_dataloader=train_dataloader,\n","        test_dataloader=test_dataloader,\n","    )"]},{"cell_type":"markdown","metadata":{"id":"_JbXi5xM1D3Y"},"source":["# Task 1. Finding the right features (40%)\n","\n","The authors of the paper argue that it doesn't really matter how we choose a subset of features. Let's make some steps towards exploring whether it's true for three different classes (`bottle`, `transistor`, `metal_nut`).\n","Design an experiment which will rank the ResNet18 features by its importance. To do so, we'll implement our variation of [permutation feature importance](https://scikit-learn.org/stable/modules/permutation_importance.html#outline-of-the-permutation-importance-algorithm) on a subset of features produced by the backbone.\n","\n","## 1.1 Preparing the data\n","- Using the test dataset, create `val_dataloader` (every even sample from the original test dataset) and `test_dataloader` (every odd sample). `SubsetRandomSampler` might be handy here.\n","- Then, create 3-fold cross validation-like process in which you'll train PADIM on the first 100 ResNet features in three equally sized subsets of train dataset in which you discard 1/3 of the data ($\\texttt{padim.train}(\\texttt{train\\_dataloader}_k)$) (see below). Again, `SubsetRandomSampler` might be handy here.\n","\n","In other words, you should have:\n","\n","- for $k=0$, the first 10 images indexes from the train dataset we should train on are `[1, 2, 4, 5, 7, 8, 10, 11, 13, 14]`,\n","- for $k=1$, that's `[0, 2, 3, 5, 6, 8, 9, 11, 12, 14]`,\n","- and for $k=2$, that's `[0, 1, 3, 4, 6, 7, 9, 10, 12, 13]`.\n","\n","For val and train, you should have `[0, 2, 4, ...]` and `[1, 3, 5, ...]` respectively (from the test dataset).\n","\n","Don't worry about the sampling order.\n","Use these names for DataLoaders `val_dataloader`, `test_dataloader`. For k-fold training, store dataloaders in `train_dataloaders: List[DataLoader]`, where each element represent different $k$.\n","For each class, store the results in `dataloaders` dictionary (defined below) - we will use this to check your solution.\n","\n","## 1.2 Calculating the importances\n","- In a given fold, each $j$-th feature shall be ranked based on the pixel-wise AUROC difference between the output of that model ($s_{k} \\leftarrow \\texttt{padim.test}(\\texttt{val\\_dataloader})$) and the output with the model with permuted $j$-th feature ($s_{k, j} \\leftarrow \\texttt{padim.test}(\\texttt{val\\_dataloader, feature\\_to\\_permute=}j)$). See also `test_permutation_importance` method stub above.\n","- Implement `permute_feature` method as follows: given the tensor with embeddings with shape `[B, C, H, W]`, by permutation of the $j$-th feature we mean randomly swapped values for $C=j$. The order of swapping shall be **different** for every image. In other words, for every image $b$ and feature $j$ you need to shuffle the last two dimensions (marked as stars in `[b, j, *, *]`) in an unique manner.\n","- Then, calculate the mean importance $i$ averaged on these folds and plot weights importance for the class ($i_j \\leftarrow s_k -  \\frac{1}{K} \\sum_{k} s_{k, j}$, where $K$ is the number of folds).\n","- Append results in `results` dictionary, where keys are class names and values are the lists of averaged feature importances (from feature 0 to feature 99).\n","\n","## 1.3 Drawing conclusions\n","\n","- Finally, for every class train three models on the full training data and evaluate it on the `test_dataloader`. The first model shall use the first 10 features, the second shall use worst 10 features (in terms of feature importance), and the third shall contain the best 10 features.\n","- Write your conclusions (with the things enlisted below in mind). Simply plotting charts or outputting logs without any comment doesn't qualify as an answer to a question.\n","\n","Note 1: Limit yourself to the first 100 features of ResNet18. If you want, you can go with all of available features instead of 100, but it'll take some time to calculate. Converting parts of the code to PyTorch and running on GPU might change a lot here, but this is not evaluated in this exercise. This experiment can be calculated without GPU in less than one hour anyway.\n","\n","Note 2: If you'd like to be fully covered, one needs to explore if the features are correlated, as this might bias the results of feature importance calculations. However, this is not evaluated in this task for the sake of simplicity (that is, examining the 100 first features without worrying about correlated features are enough to get 100% from this task)."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"SELEyEBK1D3Y","executionInfo":{"status":"ok","timestamp":1702731126768,"user_tz":-60,"elapsed":8,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[],"source":["# do not modify\n","CLASS_NAMES = ['bottle', 'transistor', 'metal_nut']\n","\n","BATCH_SIZE = 1\n","RESIZE = 256 * 2 // 4\n","CROP_SIZE = 224 * 2 // 4\n","BACKBONE = \"resnet18\"\n","NUMBER_OF_BACKBONE_FEATURES = 10\n","MAX_NUMBER_OF_BACKBONE_FEATURES = 100  # 448\n","folds = 3"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"czZpCmdu1D3Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702731126768,"user_tz":-60,"elapsed":7,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}},"outputId":"eb86ac5c-ae6f-4598-8eb2-204a2f15ebd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["1702731126.507137\n"]}],"source":["seed_all(SEED)\n","results = {c: [0] * MAX_NUMBER_OF_BACKBONE_FEATURES for c in CLASS_NAMES}\n","\n","run_timestamp = time.time()\n","print(f\"{run_timestamp}\")\n","\n","idx_all_fatures = torch.Tensor(range(MAX_NUMBER_OF_BACKBONE_FEATURES)).int()\n","idx_first_n_features = torch.Tensor(range(NUMBER_OF_BACKBONE_FEATURES)).int()\n","\n","dataloaders = {c: {\"val_dataloader\": None, \"test_dataloader\": None, \"train_dataloaders\": None} for c in CLASS_NAMES}\n","\n","# TODO: Your code for T1.1, T1.2, and T1.3 goes below. Don't forget to write `test_permutation_importance` and `permute_feature` above in the PADIM code.\n","\n","# T1.1\n","def get_train_sampler(k: int, folds: int, len_train_dataset: int):\n","  return SubsetRandomSampler([i for i in range(len_train_dataset) if i%folds != k])\n","\n","def get_train_val_test_dataloaders(class_name: str, folds: int, cross_validation = True):\n","    train_dataset = MVTecDataset(DATA_PATH, class_name=class_name, is_train=True, resize=RESIZE, cropsize=CROP_SIZE)\n","\n","    if cross_validation:\n","      train_dataloaders = [\n","        DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=get_train_sampler(k, folds, len(train_dataset)), pin_memory=True) for k in range(folds)\n","      ]\n","    else:\n","      train_dataloaders = DataLoader(train_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n","\n","\n","    test_dataset = MVTecDataset(DATA_PATH, class_name=class_name, is_train=False, resize=RESIZE, cropsize=CROP_SIZE)\n","    val_sampler = SubsetRandomSampler([i for i in range(0, len(test_dataset), 2)])\n","    test_sampler = SubsetRandomSampler([i for i in range(1, len(test_dataset), 2)])\n","    val_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, pin_memory=True)\n","    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, pin_memory=True)\n","    return train_dataloaders, val_dataloader, test_dataloader\n","\n","\n","def cross_validation(class_name, folds=3, NUMBER_OF_BACKBONE_FEATURES=100):\n","\n","  train_dataloaders, val_dataloader, test_dataloader = get_train_val_test_dataloaders(class_name, folds)\n","  dataloaders[class_name][\"train_dataloaders\"] = train_dataloaders\n","  dataloaders[class_name][\"val_dataloader\"] = val_dataloader\n","  dataloaders[class_name][\"test_dataloader\"] = test_dataloader\n","\n","  print(f\"Cross-validation for class {class_name}\")\n","  # reference score for k-th fold\n","  s_k = []\n","  # importance for j-th feature\n","  i_j = []\n","  # score for (k-th fold, j-th feature permuted)\n","  s_k_j = []\n","\n","  for k, train_dataloader in enumerate(train_dataloaders):\n","    print(f\"{k}-fold results\")\n","\n","    padim = PADIM(\n","        backbone=BACKBONE,\n","        device=DEVICE,\n","        backbone_features_idx=sample_idx(NUMBER_OF_BACKBONE_FEATURES, MAX_NUMBER_OF_BACKBONE_FEATURES),\n","        save_path=SAVE_PATH,\n","        plot_metrics=False,\n","    )\n","\n","    padim.train(train_dataloader)\n","\n","    reference = padim.test(val_dataloader)\n","    permuted = padim.test_permutation_importance(val_dataloader, list(range(NUMBER_OF_BACKBONE_FEATURES)))\n","\n","    print(f\"Reference score: {reference}\")\n","    print(f\"Feature scores: {permuted}\")\n","\n","    s_k.append(reference)\n","    s_k_j.append(permuted)\n","\n","  # T1.2\n","  s_k_j = np.array(s_k_j)\n","  s_k = np.array(s_k)\n","  mean_s_k = np.mean(s_k, axis=0)\n","  mean_s_k_j = np.mean(s_k_j, axis=0)\n","\n","  for j in range(NUMBER_OF_BACKBONE_FEATURES):\n","    score = mean_s_k - mean_s_k_j[j]\n","    i_j.append(score)\n","    results[class_name][j] = score\n","\n","  return i_j"]},{"cell_type":"code","source":["for class_name in CLASS_NAMES:\n","  importances = cross_validation(class_name, folds=3, NUMBER_OF_BACKBONE_FEATURES=100)\n","  print(f\"Feature importances {importances}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2mk6JRheY1f","executionInfo":{"status":"ok","timestamp":1702733017618,"user_tz":-60,"elapsed":1890856,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}},"outputId":"b07ac8dd-1d08-4a0a-f75a-605749f4b4fc"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Cross-validation for class bottle\n","0-fold results\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 139/139 [00:05<00:00, 25.47it/s]\n","Covariance estimation: 100%|██████████| 784/784 [00:00<00:00, 1512.48it/s]\n","Feature extraction (test): 100%|██████████| 42/42 [00:02<00:00, 18.35it/s]\n","Feature extraction (val): 100%|██████████| 42/42 [00:01<00:00, 24.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Reference score: 0.9812277566574825\n","Feature scores: [0.9808620333668195, 0.9797029412222837, 0.9801472180412312, 0.9800845876532376, 0.9811928411825978, 0.9808879720711172, 0.9805372941265085, 0.9807189596291878, 0.9801658861448436, 0.9810403530064533, 0.9811733670545622, 0.9800034593923043, 0.9811111782478429, 0.9810758320286497, 0.9810398416371257, 0.9805685784903407, 0.9809736443571366, 0.9807589790892338, 0.9809111479260826, 0.9810412908053714, 0.9809518575403077, 0.9812599841885447, 0.9806794166444427, 0.9796655034435895, 0.9807170303984047, 0.9809313467762115, 0.9808964206650453, 0.9797868432196866, 0.9761252183065198, 0.9810465923644754, 0.9809663841920482, 0.9810264166934124, 0.9793911254902438, 0.9807793872282664, 0.9809726977531839, 0.9810019792600876, 0.981262057285067, 0.9810555431714986, 0.9809210640258075, 0.9812012813979458, 0.9814961763366087, 0.9806822122304428, 0.981121595908438, 0.9807825208423111, 0.9806025247591749, 0.9810177043999809, 0.9760522294347889, 0.9812597407581815, 0.9803512924577694, 0.9812616573960087, 0.9809153008169741, 0.9809219598063972, 0.9790451157192032, 0.9808925322011387, 0.9811870292074177, 0.9806804171823693, 0.9809159188501417, 0.9806028927895604, 0.9807818693700797, 0.9804009608562286, 0.9803585543286767, 0.9810459202969917, 0.9809367290606772, 0.9811104378472687, 0.9756089598014439, 0.9810088567949894, 0.9806762741501066, 0.9807356409808071, 0.9808280948494262, 0.9804076952528729, 0.981070459301786, 0.9786824671918395, 0.9794386131750892, 0.981156031872668, 0.9803254125540459, 0.9807179440148341, 0.9811287910517311, 0.9810321559204417, 0.9791086000701424, 0.9806484072937054, 0.9807439940739734, 0.9811545464306893, 0.9809643255197282, 0.9805529114737112, 0.9808332115780566, 0.9799346831151193, 0.9807363209753306, 0.9806623325440104, 0.9790042174364121, 0.98127615896218, 0.9807264729578404, 0.9810275754460237, 0.9811185179843568, 0.9806809093110653, 0.9801528925474922, 0.9811997676343596, 0.9809973746282664, 0.9811883859604267, 0.9803657322632694, 0.9803459789328489]\n","1-fold results\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 139/139 [00:05<00:00, 25.81it/s]\n","Covariance estimation: 100%|██████████| 784/784 [00:01<00:00, 717.31it/s]\n","Feature extraction (test): 100%|██████████| 42/42 [00:01<00:00, 22.46it/s]\n","Feature extraction (val): 100%|██████████| 42/42 [00:01<00:00, 24.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Reference score: 0.9813079274273262\n","Feature scores: [0.9799204726418929, 0.9812899081117894, 0.9811575608631948, 0.9809197128167094, 0.980998642076649, 0.9806855287182867, 0.9801123652802693, 0.9807733380188588, 0.9808402976994661, 0.9806675636628361, 0.9810704653724938, 0.9807459427711581, 0.9808175675147228, 0.9809002209531765, 0.9811765216401428, 0.9807143871319808, 0.9811980017858886, 0.9809512093793713, 0.976127276151016, 0.9773764408412604, 0.9804504285450489, 0.9801324383011834, 0.9810236725077435, 0.9812425687579147, 0.9800327342264465, 0.9798922621382795, 0.9811325397137609, 0.9797734549009042, 0.9808024735277499, 0.9809654928516042, 0.9809173133820178, 0.9805561930675285, 0.9804121307577865, 0.980777409582335, 0.9808193158534665, 0.9810602196233043, 0.9808048841756909, 0.9795503018554139, 0.9811019356956503, 0.9809270699876941, 0.9815871004872196, 0.980633065812507, 0.981003745083473, 0.9813591467661853, 0.9810564927857196, 0.9813514681988884, 0.9803241817556799, 0.9794034603907199, 0.9786759356371076, 0.9812004597953842, 0.9812658696393568, 0.97898626376981, 0.9810191439604536, 0.9810124112445425, 0.9811328224281255, 0.981020353661856, 0.9810653273963863, 0.9762839429809314, 0.9812833648420968, 0.9806823182420581, 0.9811796216646104, 0.9806043419327204, 0.9806054493602573, 0.9811060922490348, 0.9810406990618802, 0.9812043231486363, 0.981280672132016, 0.980894505256411, 0.9811864860045029, 0.9809709692069543, 0.9807406736727806, 0.9805056473012873, 0.9812332519524373, 0.9798968179535831, 0.9795871810286539, 0.9804143579800458, 0.9807476815021288, 0.9812134602160104, 0.9812708575786749, 0.9810361963276409, 0.9814297228827873, 0.9807736943091978, 0.9806454596891561, 0.9784185101852985, 0.9809749598694698, 0.9808473181719412, 0.9798102904503393, 0.9809387427044005, 0.9812145081154916, 0.9813073928036758, 0.9807657729135913, 0.9811780941792176, 0.9809334795763884, 0.9808215411692225, 0.9813089849094947, 0.9809204312924963, 0.9805406469633422, 0.9809605871427818, 0.9809049735396846, 0.9809542927219355]\n","2-fold results\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 140/140 [00:06<00:00, 22.19it/s]\n","Covariance estimation: 100%|██████████| 784/784 [00:00<00:00, 1595.97it/s]\n","Feature extraction (test): 100%|██████████| 42/42 [00:01<00:00, 24.28it/s]\n","Feature extraction (val): 100%|██████████| 42/42 [00:01<00:00, 24.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Reference score: 0.9811308465632694\n","Feature scores: [0.9810601732651725, 0.9793870021250674, 0.9809841495161971, 0.9807483601169461, 0.9799542833733967, 0.980454517994536, 0.979624024204102, 0.9813545351856614, 0.9810405964117311, 0.9810551896907432, 0.9808323208647518, 0.9811859907150249, 0.9740930422678028, 0.9809816349889141, 0.9809936954281777, 0.9805003027204322, 0.9809121311549664, 0.9806383746715115, 0.9797025641109224, 0.9808881775720999, 0.9804806368383058, 0.9809207051516549, 0.9811332265315593, 0.9805732156581451, 0.9810836040898628, 0.9813998147383656, 0.9807250380883692, 0.9807783222705982, 0.9808678502086, 0.9786861451376497, 0.9811041554173243, 0.9809119661420924, 0.9808349760719068, 0.9809534228045675, 0.9805746253166194, 0.9808508107855664, 0.980442690424611, 0.9805534247997132, 0.9811947594259015, 0.9799323558766958, 0.980442436784421, 0.9805367169828185, 0.9803796361657551, 0.9800874909817573, 0.9808509336295986, 0.9803014155982303, 0.9808546588867922, 0.9809816134404101, 0.9803691681835082, 0.9796974847597901, 0.9810126944355331, 0.9792929640024124, 0.9811686906278421, 0.9806684942621958, 0.9808414828922674, 0.9807226897780675, 0.9809452199739606, 0.978528354373893, 0.980801338506087, 0.9807692647746495, 0.9798072098421022, 0.9804879905474818, 0.9806004493798659, 0.980207485619464, 0.981133523920982, 0.9809337114423043, 0.9806723538526125, 0.9771726692326277, 0.9809761541683327, 0.9806512003209774, 0.9807905817889389, 0.9811042073444525, 0.9807965400882439, 0.9807900602348701, 0.9805290407484797, 0.980010726004384, 0.9803543860854169, 0.9804739099673324, 0.9810713289432126, 0.9755520848959286, 0.9806399463325915, 0.9800378782481761, 0.9803331556915977, 0.9797246189921435, 0.9804601572555722, 0.980923134488345, 0.9810833803516714, 0.9805073181256222, 0.9810386344693659, 0.9791706031433076, 0.9804926265864355, 0.9805541099618641, 0.9805497842063154, 0.980761930306105, 0.9806661591970748, 0.9810727322801234, 0.9806697653981571, 0.9805706379403134, 0.9785316023028765, 0.9808285682392023]\n","Feature importances [0.00060795045806461, 0.001095559729645923, 0.00045920074248506637, 0.0006379566870616804, 0.0005069213384781834, 0.0005461706213795159, 0.001130949012399518, 0.0002732326047900635, 0.0005399167973457741, 0.0003011414293485615, 0.0001967924520901443, 0.0005770459231970726, 0.002548247539236548, 0.0002362808924459836, 0.0001521573142105881, 0.0006277541017749577, 0.00019425111669546524, 0.00043932250265388273, 0.0023085141533524256, 0.0014535404764489668, 0.000594535908138627, 0.0004511343355649844, 0.0002767383214442587, 0.0007284142628095625, 0.0006110539777880453, 0.0004810356650738479, 0.0003041773936343084, 0.0011093034189632034, 0.001956996201736172, 0.0009894334314496378, 0.00022622588556275858, 0.0003906515816817224, 0.0010094327760469257, 0.0003854370109697136, 0.0004332972416029035, 0.0002511736597066161, 0.00038563292090321166, 0.0008357536071508243, 0.00014959050023966025, 0.0005352744619141481, 4.693901327623706e-05, 0.0006048452074366439, 0.0003871844968039717, 0.0004791240192748569, 0.000385526491195054, 0.00033198081699292725, 0.0021451535236057806, 0.0006739053529222216, 0.0014233781232310116, 0.0005023095656316867, 0.00015755525207150622, 0.0014884476898194832, 0.0008111934468598703, 0.00036436431340047815, 0.00016839870675589008, 0.00041435667526179554, 0.0002466881425298162, 0.0027504468345646016, 0.0002666526432716365, 0.0006046622583807393, 0.0007737149375629526, 0.0005094259569614623, 0.0005079676157593305, 0.0004141716441036225, 0.0019611159545908086, 0.00017321308738271757, 0.0003457435044477153, 0.0016212383927441953, 0.00022526520860555177, 0.0005455552890912818, 0.00035493862819091504, 0.0011247362701664043, 0.000732708477435895, 0.0006078735289856141, 0.0010749654389662355, 0.0008411675496048376, 0.00047855733626722685, 0.0003156681814312501, 0.0007385813520160989, 0.002143280710267814, 0.0002842891195754538, 0.0005668038866716296, 0.0005745299158653738, 0.0016568299989750956, 0.0004660673149931016, 0.0006537982908909612, 0.000678846290245616, 0.0005193790913483598, 0.0008030568756028922, 0.0006374585796383725, 0.000560552730070274, 0.0003022503536574961, 0.00035491629367256916, 0.00046738328722850664, 0.0005128313313388366, 0.0001578664803663088, 0.00048624788610418523, 0.00031563986818550216, 0.0012880741807491658, 0.000512563584697201]\n","\n","Cross-validation for class transistor\n","0-fold results\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 142/142 [00:08<00:00, 16.33it/s]\n","Covariance estimation: 100%|██████████| 784/784 [00:01<00:00, 718.18it/s]\n","Feature extraction (test): 100%|██████████| 50/50 [00:03<00:00, 13.88it/s]\n","Feature extraction (val): 100%|██████████| 50/50 [00:03<00:00, 15.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Reference score: 0.970641284464745\n","Feature scores: [0.9682743758386182, 0.9711082040318049, 0.9696001777316341, 0.9704391231743164, 0.9697056309878688, 0.9677628227376656, 0.9676605735148602, 0.9680540429055611, 0.9659895790846458, 0.9704593652015415, 0.9695181292885254, 0.9685219005467353, 0.9705947253294691, 0.969616453523757, 0.96921245980418, 0.9702061960104702, 0.9707866091179882, 0.9683078239642275, 0.9703134771465489, 0.9706760925520902, 0.9611929385552269, 0.9670467990331841, 0.9694331541357971, 0.9699731159894261, 0.9701542143829289, 0.9703941450480379, 0.9693530949863987, 0.9681503990412912, 0.9701667607402563, 0.9700777859814197, 0.9708907828232276, 0.9665588635869932, 0.9713915019097367, 0.9715087473736695, 0.9691449470779299, 0.9690998483684503, 0.9694526572618148, 0.9706167702247395, 0.9716797856923953, 0.9693794000054128, 0.971061356975615, 0.9690119113798826, 0.9700143155129772, 0.9664294683563326, 0.9704088032788323, 0.9705784034410391, 0.971772639057276, 0.9709625040479908, 0.9695626286582492, 0.9714114950914992, 0.9697118959389668, 0.9697336805579432, 0.969912452086206, 0.9688857134908984, 0.9693843576073142, 0.9695946815862019, 0.9678683110323594, 0.9689258633306658, 0.9702284967501189, 0.965455425475436, 0.9708179551335083, 0.969149065533965, 0.970788715177309, 0.969998846285561, 0.9706391855798613, 0.9715920471746491, 0.9700483797845159, 0.9718812688120204, 0.9698323384154731, 0.9699641825865063, 0.9690872705927928, 0.9705590560463822, 0.9706651225085626, 0.968611889512093, 0.9709437008574299, 0.9702416693019758, 0.9699985292500348, 0.9712762229875528, 0.9698026351924827, 0.9720983760347557, 0.9716565289315693, 0.9718428669898609, 0.9695192585054428, 0.9696721203547014, 0.9697607880827317, 0.9691731332255924, 0.9702120380646987, 0.9711149300337366, 0.9709464906164783, 0.968602973551612, 0.9669052417931787, 0.9704248519682057, 0.9693165076166964, 0.9712441491725538, 0.9680951433472827, 0.9685024193608924, 0.9681765629191608, 0.9704138067137588, 0.9710656797604982, 0.970315890346377]\n","1-fold results\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 142/142 [00:09<00:00, 14.87it/s]\n","Covariance estimation: 100%|██████████| 784/784 [00:00<00:00, 1502.68it/s]\n","Feature extraction (test): 100%|██████████| 50/50 [00:03<00:00, 15.89it/s]\n","Feature extraction (val): 100%|██████████| 50/50 [00:03<00:00, 16.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Reference score: 0.9689895401683924\n","Feature scores: [0.9699984442099174, 0.9696039021640699, 0.967970332757492, 0.9675662330010504, 0.9684082305195109, 0.9704631240800515, 0.9677808332955309, 0.9670591337555852, 0.9695596151752383, 0.9688369728659808, 0.9684838712248638, 0.9688220826397779, 0.9693111396896457, 0.9671211073994813, 0.9664641570233063, 0.9677408553570331, 0.9684097561076265, 0.9627620776545945, 0.9692914841891137, 0.9679438672899795, 0.9680674532669726, 0.9704077177009226, 0.9686339507966737, 0.9651235297592445, 0.9680560834076394, 0.9686353108681105, 0.9672253832801145, 0.968070385351935, 0.9663895137402407, 0.9689859938243558, 0.9684983516305413, 0.9694336753465901, 0.9691870311415687, 0.9661357658551186, 0.9685002134518359, 0.967925609203062, 0.9672159139884249, 0.9690021084220143, 0.9696286359155243, 0.9696247474144615, 0.9687935172342533, 0.9602185676467766, 0.9678827233137941, 0.968996445619014, 0.9690790661083007, 0.969127585685957, 0.9641482905464356, 0.9675766929574536, 0.9661573686119859, 0.9685837575127817, 0.9679295488247321, 0.9696335364949115, 0.967061069120346, 0.9696409115749749, 0.966488082915584, 0.9673476553258586, 0.9691093983122229, 0.9709101879863649, 0.9682551389346817, 0.9689224515018408, 0.9709646988333784, 0.9667483601747914, 0.9682053231095574, 0.969070734787658, 0.9685921201859341, 0.9679954888353717, 0.966943341740473, 0.9663349013760383, 0.9681598611366036, 0.968054053327144, 0.9700547663061226, 0.9628572372828912, 0.9688838387029602, 0.9691639706575464, 0.9677344432751227, 0.9671273843299147, 0.9667598161273706, 0.9686187088914086, 0.9698902888236927, 0.9687833216130763, 0.9617623815095167, 0.968672638872294, 0.96971497620787, 0.9682845786342325, 0.962853904877499, 0.9687886890355031, 0.9678741629157862, 0.9683908284723941, 0.9680758537649865, 0.9677670181378939, 0.9680203131339276, 0.9692964633801471, 0.9677110129236335, 0.968982009093686, 0.969049509204336, 0.9691169374389734, 0.966155599773152, 0.9690372321626546, 0.9677747068308161, 0.9688262226410647]\n","2-fold results\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 142/142 [00:09<00:00, 14.72it/s]\n","Covariance estimation: 100%|██████████| 784/784 [00:00<00:00, 1545.68it/s]\n","Feature extraction (test): 100%|██████████| 50/50 [00:03<00:00, 16.14it/s]\n","Feature extraction (val): 100%|██████████| 50/50 [00:04<00:00, 12.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Reference score: 0.970946060720693\n","Feature scores: [0.971134878040679, 0.9695638170916986, 0.9665799407450325, 0.9690963322579746, 0.9725091692339097, 0.9701808119961145, 0.9687051367031115, 0.9702437783671003, 0.9709059079409421, 0.9697685671472339, 0.9711678766998669, 0.9700632148969998, 0.9712407164347423, 0.9708957004062502, 0.9687693699217315, 0.9684061874065517, 0.9684694892647506, 0.9701063038425854, 0.9703964826200834, 0.9701912303100659, 0.970282537770229, 0.9703287690534725, 0.9704315648060323, 0.9703704196231375, 0.9717176018874087, 0.9694574940172332, 0.9717151777613736, 0.9714533925100709, 0.969873629912237, 0.9719040417919917, 0.9704613436787458, 0.967391250255756, 0.9702664920208391, 0.9727952155356007, 0.9711261242400301, 0.9711493279933938, 0.9710523841462009, 0.9669592296961257, 0.9707934177466183, 0.968355745540479, 0.970519793313703, 0.9705351876593027, 0.9697511899363952, 0.9733252292532245, 0.969287136107209, 0.9709965005682695, 0.9673525330655236, 0.969904464239, 0.9713007980896031, 0.9692024190806374, 0.9698638303989762, 0.9680762889922343, 0.9727127833588343, 0.9693872122653997, 0.9696384584879092, 0.9713520272788491, 0.9685986313935543, 0.9675088515015635, 0.9705897626374473, 0.9713494988711632, 0.9706518954353713, 0.9703971453450038, 0.970477199338461, 0.9711019670763696, 0.9701973376429482, 0.9715639683583215, 0.9699036185769019, 0.9710694669418339, 0.9697622508341865, 0.9708165629197154, 0.9595332595946524, 0.9701349246689916, 0.9694295969094338, 0.9708814862884743, 0.9712694812764558, 0.9671122212118175, 0.9687940081676049, 0.9704683845002458, 0.9675937051057236, 0.972062323127712, 0.9674933622866482, 0.9684231228519705, 0.9706865904430556, 0.9694152941752918, 0.9723617940958085, 0.9716861147307441, 0.9691180874112962, 0.9705868226759621, 0.9705600662597914, 0.9708153271174287, 0.9691845459121468, 0.9698581515357678, 0.9693170475643985, 0.9700490756610405, 0.9692154592235391, 0.9723391073846044, 0.9701479379351793, 0.9710206956226118, 0.970977007754134, 0.9704161884074958]\n","Feature importances [0.0003897290882052262, 0.00010032068875232003, 0.0021421447065572696, 0.001158398973496344, -1.538179581961341e-05, 0.0007233755133329023, 0.0021434472801092896, 0.0017399767751946627, 0.0013739277176680886, 0.0005039933796913143, 0.00046900271352479095, 0.0010565624234392113, -0.00018989870000885034, 0.0009812080081139651, 0.0020436328682041927, 0.0014078821932584917, 0.000970343621155001, 0.0031335599641409972, 0.00019181379936139553, 0.0005885650672314835, 0.0036779852538005864, 0.0009311998554168976, 0.0006927385384424278, 0.0017032733273407707, 0.00021632855861775102, 0.0006966451401495544, 0.0007610764419812011, 0.000967569483511177, 0.001382326987032112, -0.0001303120813122005, 0.0002421357404386315, 0.002397698721496977, -8.937990610469182e-05, 4.571886314730378e-05, 0.0006018668613447797, 0.0008006999296413797, 0.0009519766524632711, 0.0013329256703169534, -0.0005083180002357635, 0.0010723307978257601, 6.740594341958506e-05, 0.0036037395559561647, 0.0009762188635545899, 0.000608580708419848, 0.000600626619829403, -4.186811381168276e-05, 0.0024344742281983134, 0.0007110747031287001, 0.001185363331330791, 0.0004597378896373794, 0.0010238700637184017, 0.0010444597695804525, 0.00029686026281483535, 0.000887682674185819, 0.001688662114340933, 0.0007608403876402381, 0.0016668482052312195, 0.001077327511745385, 0.0005011623438608837, 0.0016165031684636233, -0.0006192213494758958, 0.001427438100023437, 0.0003685492428343595, 0.0001351124014138394, 0.000382747315029075, -0.00019153967150387086, 0.0012271817506464, 0.0004304160746460006, 0.0009408116558558, 0.0005806955068214936, 0.003967196286754238, 0.002341889118521845, 0.0005327757442912251, 0.0006398462985722775, 0.00020975331494066385, 0.002031870170040806, 0.0016748439362733736, 7.11896582077376e-05, 0.0010967520773104145, -0.0007890451405712096, 0.003221537542032138, 0.0005460855465684311, 0.00021868673248737203, 0.0010682973965348008, 0.0018667994325971549, 0.0003096494539970296, 0.0011241989873497227, 0.00016143472391250135, 0.0003314915708581001, 0.0011305221822985878, 0.0021555948381923873, 0.0003324728232365626, 0.001410772416367334, 0.00010055047551671414, 0.0014055911928908538, 0.00020614038978683524, 0.002032261575446115, 3.5050284935111975e-05, 0.0002531636694607098, 0.0003395279862977718]\n","\n","Cross-validation for class metal_nut\n","0-fold results\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 146/146 [00:04<00:00, 30.21it/s]\n","Covariance estimation: 100%|██████████| 784/784 [00:00<00:00, 1524.55it/s]\n","Feature extraction (test): 100%|██████████| 58/58 [00:01<00:00, 30.95it/s]\n","Feature extraction (val): 100%|██████████| 58/58 [00:02<00:00, 24.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Reference score: 0.9622941698817207\n","Feature scores: [0.9605802097383243, 0.9611570747204329, 0.961775042986298, 0.9585746843696715, 0.9592925765744666, 0.9614796144865424, 0.9612428512056193, 0.9601652461669482, 0.961689158186477, 0.9603919984754632, 0.9601381750579844, 0.9601233448835829, 0.9600763086099956, 0.9596014415898189, 0.9605379241192437, 0.9614864302110017, 0.9574368005820848, 0.9615906502026712, 0.9602893458677749, 0.9612573311004134, 0.9617074738587273, 0.961060386787214, 0.9598851151187173, 0.9609937698798396, 0.9548448434367215, 0.9614458720276041, 0.9615244063139979, 0.9589276177640782, 0.9614293816967201, 0.9591694091990052, 0.9601621061007014, 0.9615753421996066, 0.9611068498705317, 0.9618460868875707, 0.9616176287117408, 0.9601989992599775, 0.9608003039876027, 0.952011678995987, 0.9575359957968439, 0.9615084890908322, 0.9615309508653812, 0.9603023884717209, 0.9616826120591171, 0.9606542563857313, 0.9594874769358028, 0.9598091656294085, 0.9603990770953679, 0.959555352238144, 0.9593251023042632, 0.9617020173542273, 0.9547931901214421, 0.9574285666285919, 0.9606425283790869, 0.9614334233642889, 0.9602235925656726, 0.960991557921344, 0.9592140215151976, 0.959851506370154, 0.9620597550388845, 0.9615661373018121, 0.9610055029296098, 0.9615891049424024, 0.9600358657956052, 0.9587804382806544, 0.9566249726549205, 0.9611100023344628, 0.9563393483669208, 0.9584674983221088, 0.9613065942517435, 0.9596279295948686, 0.9598036820331166, 0.9609928172093642, 0.960671482727803, 0.960339959518659, 0.9619993429248077, 0.960691716573958, 0.961732640219608, 0.9603603672926165, 0.9607473520224064, 0.9611822043460446, 0.9621458047684307, 0.9618245854907741, 0.961847361867817, 0.9611459274387281, 0.9621256874469989, 0.9616234030757537, 0.9604405670788049, 0.9614802851247112, 0.9551690537907792, 0.9607303882230613, 0.9603681769781435, 0.9618537960257774, 0.9592979559086358, 0.9609044375782201, 0.9614819374463378, 0.9573714362310585, 0.9616054783132933, 0.9608528750166909, 0.961791365888408, 0.9603544715933988]\n","1-fold results\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 147/147 [00:05<00:00, 28.02it/s]\n","Covariance estimation: 100%|██████████| 784/784 [00:00<00:00, 1477.74it/s]\n","Feature extraction (test): 100%|██████████| 58/58 [00:01<00:00, 31.69it/s]\n","Feature extraction (val): 100%|██████████| 58/58 [00:01<00:00, 33.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Reference score: 0.9624873220720216\n","Feature scores: [0.9611438509692101, 0.9526848808137005, 0.9614011048229102, 0.9618510899084967, 0.9612054138615514, 0.9587818895226499, 0.9606811031956723, 0.9610889431267396, 0.9609445390360342, 0.9616167429302239, 0.9621465527045096, 0.9619610010826224, 0.9582353122181689, 0.9605426106089803, 0.9618049660654436, 0.9619482764207403, 0.9571576871345738, 0.9615349602179208, 0.9622224800550965, 0.9612624641169122, 0.9604584878863137, 0.9597834843443723, 0.9612666966202632, 0.9618288148346669, 0.9616669385495075, 0.9624837651148814, 0.9613836966356287, 0.9614416244023805, 0.9617231117287471, 0.9611688683102264, 0.9621942128622869, 0.9613388784293234, 0.9608809787882102, 0.9574461923081775, 0.962226912534895, 0.9599338226181483, 0.9606736532756319, 0.9619927871989985, 0.9560681037791134, 0.960582181570487, 0.9622945700297367, 0.9608245436140834, 0.9601100240596933, 0.9619198799828232, 0.9608196657407252, 0.9621568662944834, 0.9600444794994712, 0.961826703025745, 0.9619151816807653, 0.9567386148640817, 0.9594172558745353, 0.959603126091391, 0.9607590685544386, 0.9619038839683218, 0.9604571720207261, 0.9600799613114792, 0.9618594446643641, 0.9603066051852852, 0.9612369501555851, 0.9624167015831845, 0.959790159086449, 0.9606725917651964, 0.9539106305615527, 0.9616980807742928, 0.9618392819998282, 0.9614350176824645, 0.9603755646395953, 0.9592950350982862, 0.9598861699199944, 0.9610363658387723, 0.9601328059901784, 0.9620251890495133, 0.9603627327587578, 0.9606779953619036, 0.9602459920666235, 0.9613998916359637, 0.9595496538662318, 0.9620854270031436, 0.9618401971695602, 0.960364602092391, 0.9598900788452882, 0.9609260305767924, 0.9608009683518829, 0.9617568056325904, 0.9615877569043738, 0.9621520989121085, 0.9620157284907573, 0.9610354582487383, 0.9578158676944504, 0.9595428610759875, 0.9569916158167883, 0.9619160369183507, 0.9613991943487777, 0.9579518511834767, 0.9603377054590688, 0.9604162995650394, 0.961630080692112, 0.9598921571159227, 0.9620098855492396, 0.9587952737308256]\n","2-fold results\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 147/147 [00:04<00:00, 33.85it/s]\n","Covariance estimation: 100%|██████████| 784/784 [00:00<00:00, 1458.20it/s]\n","Feature extraction (test): 100%|██████████| 58/58 [00:01<00:00, 31.49it/s]\n","Feature extraction (val): 100%|██████████| 58/58 [00:02<00:00, 26.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Reference score: 0.9627113380720431\n","Feature scores: [0.9595954945587852, 0.9607249233808935, 0.960198809294735, 0.9615819321166079, 0.9619484107389922, 0.9608921286440106, 0.9619504918313756, 0.9619171528375093, 0.9614407400242333, 0.9617918446326388, 0.9624215399595621, 0.962169748554046, 0.9608014639440562, 0.9613785338181591, 0.9580892508827853, 0.961536689762411, 0.9621012303282142, 0.960312064796711, 0.9620450217570383, 0.961804842681469, 0.9607877739813704, 0.9604520419535554, 0.9616810234970092, 0.9622159933345575, 0.9609271253478432, 0.9615449126990755, 0.9624420132791455, 0.9620469118860605, 0.9625977079528756, 0.9621463384617196, 0.9595812829852993, 0.9622476607198428, 0.960160708667057, 0.9591608131986118, 0.960214638450816, 0.9619746004791744, 0.9626997281360803, 0.9524024006669731, 0.9614749379930015, 0.9598206951905542, 0.9609069817526267, 0.9605875175577894, 0.9585181864716679, 0.9613380222986844, 0.9575813344432235, 0.960909326333323, 0.9595940437745735, 0.9572679588021372, 0.9623684474247391, 0.9608223191603432, 0.954367847354429, 0.9616787998237527, 0.9619526840601426, 0.954980419408164, 0.9610954163839339, 0.9602697461646685, 0.9612982901672829, 0.9604309550311546, 0.9604930452303265, 0.9622422173259688, 0.962084676973267, 0.961153277029083, 0.962172564171696, 0.9604825554086225, 0.9616612962598559, 0.9623214748881567, 0.9613368932088624, 0.9578454821373, 0.9601293351263996, 0.9614185360419668, 0.9618813342992948, 0.9614213788564737, 0.959037789597263, 0.9614623948836477, 0.9606409718618407, 0.9625521486847521, 0.9622353550051287, 0.9598037339052675, 0.9618404122003387, 0.9621855081795311, 0.9609422788901715, 0.9598723363257844, 0.9615301367532857, 0.9623316647564464, 0.9613295039038918, 0.960509489992967, 0.9617891834006786, 0.9569388717079234, 0.9612029744520793, 0.9602228091476016, 0.9622587754913975, 0.9613682156428432, 0.9558388408119652, 0.9609251730277744, 0.9617747154157662, 0.9600672374600995, 0.961973057402759, 0.9600138060002071, 0.961718114779084, 0.9599245421485135]\n","Feature importances [0.0020577582531552396, 0.004308650370252853, 0.0013726243072808009, 0.0018283745436696863, 0.0016821429502583696, 0.002113065790860791, 0.001206127931039358, 0.0014404959648627313, 0.0011394642596802562, 0.001230747995819903, 0.000928854101243104, 0.0010795785018445914, 0.0027932484178548878, 0.001990081336275762, 0.0023535629861042295, 0.0008404778772108656, 0.0035990373269707554, 0.0013517182694940955, 0.000978660781958518, 0.0010560640423302736, 0.0015130314331246453, 0.0020656389802146125, 0.0015533315965985395, 0.0008180839922403704, 0.0033513075639044487, 0.0006727600614081508, 0.0007142379323377135, 0.0016922253244220364, 0.0005808762158142633, 0.0016694046849446975, 0.0018517426924993252, 0.0007769828923375188, 0.0017814308999954953, 0.0030132458771418014, 0.0011445501094445865, 0.001795135889495092, 0.00110638154215692, 0.007028654387942201, 0.004137930818942093, 0.0018604880579706773, 0.0009201091260134797, 0.0019261267940638982, 0.002394002478435797, 0.0011935571195155203, 0.0032014509686778547, 0.0015391572561901379, 0.0024850765521242657, 0.002947605319919777, 0.0012946995386725613, 0.0027432928823776237, 0.006304845558459671, 0.0029274458273499393, 0.0013795163440391, 0.003058367761670233, 0.0019055496851509979, 0.0020505215427645274, 0.0017070245596468858, 0.002301254479730397, 0.0012343598669963818, 0.0004225912716067093, 0.0015374970121531106, 0.001359285429701207, 0.003791256498977158, 0.0021772518540719155, 0.002455759703727023, 0.0008754450402338465, 0.0031470079368024484, 0.003961604822696807, 0.0020569102425492813, 0.0018033328500591805, 0.0018916692343985408, 0.001017814970144748, 0.002473608313987241, 0.0016708267538584343, 0.0015355077241712145, 0.0009496910437039041, 0.0013250603116056192, 0.0017477672749192097, 0.0010216228778267, 0.00125350513593947, 0.0015048891739649628, 0.0016232925441448387, 0.0011047876842665838, 0.0007528107326734146, 0.0008166272568401745, 0.0010692793483187968, 0.0010824503518481743, 0.00267940498147079, 0.00443497802949222, 0.002332257193044973, 0.002624753913151978, 0.0007849271462713192, 0.0036522796521355483, 0.002570456078771488, 0.0012994905682042202, 0.003212618923195909, 0.0007614045392071445, 0.002244663964321547, 0.0006578212696846109, 0.002806180851015694]\n","\n"]}]},{"cell_type":"code","source":["import plotly.express as px\n","\n","px.bar(results, barmode='group')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"rBrdjYPE5VcD","executionInfo":{"status":"ok","timestamp":1702733018942,"user_tz":-60,"elapsed":1326,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}},"outputId":"4486f6ab-acc1-4f86-e277-40cb35266397"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"3a2b89b3-58fd-4b33-956d-b6b1de458150\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3a2b89b3-58fd-4b33-956d-b6b1de458150\")) {                    Plotly.newPlot(                        \"3a2b89b3-58fd-4b33-956d-b6b1de458150\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=bottle\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"bottle\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"bottle\",\"offsetgroup\":\"bottle\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"xaxis\":\"x\",\"y\":[0.00060795045806461,0.001095559729645923,0.00045920074248506637,0.0006379566870616804,0.0005069213384781834,0.0005461706213795159,0.001130949012399518,0.0002732326047900635,0.0005399167973457741,0.0003011414293485615,0.0001967924520901443,0.0005770459231970726,0.002548247539236548,0.0002362808924459836,0.0001521573142105881,0.0006277541017749577,0.00019425111669546524,0.00043932250265388273,0.0023085141533524256,0.0014535404764489668,0.000594535908138627,0.0004511343355649844,0.0002767383214442587,0.0007284142628095625,0.0006110539777880453,0.0004810356650738479,0.0003041773936343084,0.0011093034189632034,0.001956996201736172,0.0009894334314496378,0.00022622588556275858,0.0003906515816817224,0.0010094327760469257,0.0003854370109697136,0.0004332972416029035,0.0002511736597066161,0.00038563292090321166,0.0008357536071508243,0.00014959050023966025,0.0005352744619141481,4.693901327623706e-05,0.0006048452074366439,0.0003871844968039717,0.0004791240192748569,0.000385526491195054,0.00033198081699292725,0.0021451535236057806,0.0006739053529222216,0.0014233781232310116,0.0005023095656316867,0.00015755525207150622,0.0014884476898194832,0.0008111934468598703,0.00036436431340047815,0.00016839870675589008,0.00041435667526179554,0.0002466881425298162,0.0027504468345646016,0.0002666526432716365,0.0006046622583807393,0.0007737149375629526,0.0005094259569614623,0.0005079676157593305,0.0004141716441036225,0.0019611159545908086,0.00017321308738271757,0.0003457435044477153,0.0016212383927441953,0.00022526520860555177,0.0005455552890912818,0.00035493862819091504,0.0011247362701664043,0.000732708477435895,0.0006078735289856141,0.0010749654389662355,0.0008411675496048376,0.00047855733626722685,0.0003156681814312501,0.0007385813520160989,0.002143280710267814,0.0002842891195754538,0.0005668038866716296,0.0005745299158653738,0.0016568299989750956,0.0004660673149931016,0.0006537982908909612,0.000678846290245616,0.0005193790913483598,0.0008030568756028922,0.0006374585796383725,0.000560552730070274,0.0003022503536574961,0.00035491629367256916,0.00046738328722850664,0.0005128313313388366,0.0001578664803663088,0.00048624788610418523,0.00031563986818550216,0.0012880741807491658,0.000512563584697201],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=transistor\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"transistor\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"transistor\",\"offsetgroup\":\"transistor\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"xaxis\":\"x\",\"y\":[0.0003897290882052262,0.00010032068875232003,0.0021421447065572696,0.001158398973496344,-1.538179581961341e-05,0.0007233755133329023,0.0021434472801092896,0.0017399767751946627,0.0013739277176680886,0.0005039933796913143,0.00046900271352479095,0.0010565624234392113,-0.00018989870000885034,0.0009812080081139651,0.0020436328682041927,0.0014078821932584917,0.000970343621155001,0.0031335599641409972,0.00019181379936139553,0.0005885650672314835,0.0036779852538005864,0.0009311998554168976,0.0006927385384424278,0.0017032733273407707,0.00021632855861775102,0.0006966451401495544,0.0007610764419812011,0.000967569483511177,0.001382326987032112,-0.0001303120813122005,0.0002421357404386315,0.002397698721496977,-8.937990610469182e-05,4.571886314730378e-05,0.0006018668613447797,0.0008006999296413797,0.0009519766524632711,0.0013329256703169534,-0.0005083180002357635,0.0010723307978257601,6.740594341958506e-05,0.0036037395559561647,0.0009762188635545899,0.000608580708419848,0.000600626619829403,-4.186811381168276e-05,0.0024344742281983134,0.0007110747031287001,0.001185363331330791,0.0004597378896373794,0.0010238700637184017,0.0010444597695804525,0.00029686026281483535,0.000887682674185819,0.001688662114340933,0.0007608403876402381,0.0016668482052312195,0.001077327511745385,0.0005011623438608837,0.0016165031684636233,-0.0006192213494758958,0.001427438100023437,0.0003685492428343595,0.0001351124014138394,0.000382747315029075,-0.00019153967150387086,0.0012271817506464,0.0004304160746460006,0.0009408116558558,0.0005806955068214936,0.003967196286754238,0.002341889118521845,0.0005327757442912251,0.0006398462985722775,0.00020975331494066385,0.002031870170040806,0.0016748439362733736,7.11896582077376e-05,0.0010967520773104145,-0.0007890451405712096,0.003221537542032138,0.0005460855465684311,0.00021868673248737203,0.0010682973965348008,0.0018667994325971549,0.0003096494539970296,0.0011241989873497227,0.00016143472391250135,0.0003314915708581001,0.0011305221822985878,0.0021555948381923873,0.0003324728232365626,0.001410772416367334,0.00010055047551671414,0.0014055911928908538,0.00020614038978683524,0.002032261575446115,3.5050284935111975e-05,0.0002531636694607098,0.0003395279862977718],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=metal_nut\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"metal_nut\",\"marker\":{\"color\":\"#00cc96\",\"pattern\":{\"shape\":\"\"}},\"name\":\"metal_nut\",\"offsetgroup\":\"metal_nut\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"xaxis\":\"x\",\"y\":[0.0020577582531552396,0.004308650370252853,0.0013726243072808009,0.0018283745436696863,0.0016821429502583696,0.002113065790860791,0.001206127931039358,0.0014404959648627313,0.0011394642596802562,0.001230747995819903,0.000928854101243104,0.0010795785018445914,0.0027932484178548878,0.001990081336275762,0.0023535629861042295,0.0008404778772108656,0.0035990373269707554,0.0013517182694940955,0.000978660781958518,0.0010560640423302736,0.0015130314331246453,0.0020656389802146125,0.0015533315965985395,0.0008180839922403704,0.0033513075639044487,0.0006727600614081508,0.0007142379323377135,0.0016922253244220364,0.0005808762158142633,0.0016694046849446975,0.0018517426924993252,0.0007769828923375188,0.0017814308999954953,0.0030132458771418014,0.0011445501094445865,0.001795135889495092,0.00110638154215692,0.007028654387942201,0.004137930818942093,0.0018604880579706773,0.0009201091260134797,0.0019261267940638982,0.002394002478435797,0.0011935571195155203,0.0032014509686778547,0.0015391572561901379,0.0024850765521242657,0.002947605319919777,0.0012946995386725613,0.0027432928823776237,0.006304845558459671,0.0029274458273499393,0.0013795163440391,0.003058367761670233,0.0019055496851509979,0.0020505215427645274,0.0017070245596468858,0.002301254479730397,0.0012343598669963818,0.0004225912716067093,0.0015374970121531106,0.001359285429701207,0.003791256498977158,0.0021772518540719155,0.002455759703727023,0.0008754450402338465,0.0031470079368024484,0.003961604822696807,0.0020569102425492813,0.0018033328500591805,0.0018916692343985408,0.001017814970144748,0.002473608313987241,0.0016708267538584343,0.0015355077241712145,0.0009496910437039041,0.0013250603116056192,0.0017477672749192097,0.0010216228778267,0.00125350513593947,0.0015048891739649628,0.0016232925441448387,0.0011047876842665838,0.0007528107326734146,0.0008166272568401745,0.0010692793483187968,0.0010824503518481743,0.00267940498147079,0.00443497802949222,0.002332257193044973,0.002624753913151978,0.0007849271462713192,0.0036522796521355483,0.002570456078771488,0.0012994905682042202,0.003212618923195909,0.0007614045392071445,0.002244663964321547,0.0006578212696846109,0.002806180851015694],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('3a2b89b3-58fd-4b33-956d-b6b1de458150');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","source":["for class_name in CLASS_NAMES:\n","\n","  print(f\"Training of class: {class_name}\")\n","\n","  ten_first = list(range(10))\n","  s = pd.Series(results[class_name])\n","  ten_worst = s.sort_values(ascending=True)[:10].index.tolist()\n","  ten_best = s.sort_values(ascending=False)[:10].index.tolist()\n","  features_set = [ten_first, ten_worst, ten_best]\n","\n","  names = ['Ten first', 'Ten worst', 'Ten best']\n","\n","  train_dataloaders, val_dataloader, test_dataloader = get_train_val_test_dataloaders(class_name, folds=-1, cross_validation = False)\n","\n","  for name, features in zip(names, features_set):\n","      print(name)\n","      padim = PADIM(\n","            backbone=BACKBONE,\n","            device=DEVICE,\n","            backbone_features_idx=torch.tensor(features),\n","            save_path=SAVE_PATH,\n","            plot_metrics=False,\n","        )\n","\n","      test_score = padim.train_and_test(train_dataloader, test_dataloader)\n","      print(f\"Score = {test_score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKMHyTtZuK6o","executionInfo":{"status":"ok","timestamp":1702733213036,"user_tz":-60,"elapsed":194098,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}},"outputId":"87049686-8c6c-493e-b9ab-670052b2bcd9"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Training of class: bottle\n","Ten first\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 105/105 [00:09<00:00, 11.51it/s]\n","Covariance estimation: 100%|██████████| 3136/3136 [00:00<00:00, 7300.46it/s]\n","Feature extraction (test): 100%|██████████| 41/41 [00:01<00:00, 24.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Score = 0.44793855077645645\n","Ten worst\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 105/105 [00:09<00:00, 11.02it/s]\n","Covariance estimation: 100%|██████████| 3136/3136 [00:00<00:00, 5896.11it/s]\n","Feature extraction (test): 100%|██████████| 41/41 [00:01<00:00, 24.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Score = 0.4595422683551138\n","Ten best\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 105/105 [00:12<00:00,  8.30it/s]\n","Covariance estimation: 100%|██████████| 3136/3136 [00:00<00:00, 4058.92it/s]\n","Feature extraction (test): 100%|██████████| 41/41 [00:03<00:00, 13.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Score = 0.418244167823397\n","Training of class: transistor\n","Ten first\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 105/105 [00:14<00:00,  7.40it/s]\n","Covariance estimation: 100%|██████████| 3136/3136 [00:00<00:00, 6759.14it/s]\n","Feature extraction (test): 100%|██████████| 50/50 [00:03<00:00, 16.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Score = 0.4976295571128884\n","Ten worst\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 105/105 [00:08<00:00, 11.86it/s]\n","Covariance estimation: 100%|██████████| 3136/3136 [00:00<00:00, 4909.89it/s]\n","Feature extraction (test): 100%|██████████| 50/50 [00:03<00:00, 16.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Score = 0.5063608607179615\n","Ten best\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 105/105 [00:09<00:00, 11.12it/s]\n","Covariance estimation: 100%|██████████| 3136/3136 [00:00<00:00, 6406.38it/s]\n","Feature extraction (test): 100%|██████████| 50/50 [00:03<00:00, 12.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Score = 0.3599113383910873\n","Training of class: metal_nut\n","Ten first\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 105/105 [00:08<00:00, 11.85it/s]\n","Covariance estimation: 100%|██████████| 3136/3136 [00:00<00:00, 5950.81it/s]\n","Feature extraction (test): 100%|██████████| 57/57 [00:01<00:00, 32.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Score = 0.41833034803064\n","Ten worst\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 105/105 [00:09<00:00, 11.16it/s]\n","Covariance estimation: 100%|██████████| 3136/3136 [00:00<00:00, 3993.45it/s]\n","Feature extraction (test): 100%|██████████| 57/57 [00:02<00:00, 28.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Score = 0.39992402217193224\n","Ten best\n"]},{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 105/105 [00:09<00:00, 10.53it/s]\n","Covariance estimation: 100%|██████████| 3136/3136 [00:00<00:00, 5934.44it/s]\n","Feature extraction (test): 100%|██████████| 57/57 [00:01<00:00, 32.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Score = 0.5303873107024257\n"]}]},{"cell_type":"code","source":["\"\"\" Task 1.3\n","          bottle | transistor | metal_nut\n","Ten_first 44%    | 49%        | 41%\n","Ten_worst 48%    | 41%        | 38%\n","Ten_best  49%    | 49%        | 41%\n","\n","Each cell table represent pxl_auroc score.\n","We can see indeed that Ten_best score >= Ten_first >= Ten_worst for transistor and metal_nut classes.\n","However, this is not the case in bottle class as Ten_worst >= Ten_first. Moreover, in transistor and\n","metal_nut classes performance is the same for Ten_first and Ten_best. Therefore, we can't say that\n","there's some strong statistical correlation between best, worst, first 10 features.\n","\n","To formally reject that hyptohesis I'd apply\n","\"\"\""],"metadata":{"id":"HxLvzHQirq4F","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1702733213037,"user_tz":-60,"elapsed":41,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}},"outputId":"8e16fdf5-e55c-4321-bd5c-ba8c7169b630"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\" Task 1.3\\n          bottle | transistor | metal_nut\\nTen_first 44%    | 49%        | 41%\\nTen_worst 48%    | 41%        | 38%\\nTen_best  49%    | 49%        | 41%\\n\\nEach cell table represent pxl_auroc score.\\nWe can see indeed that Ten_best score >= Ten_first >= Ten_worst for transistor and metal_nut classes.\\nHowever, this is not the case in bottle class as Ten_worst >= Ten_first. Therefore, we can't say that\\nthere's some strong statistical correlation between best, worst, first 10 features.\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","execution_count":18,"metadata":{"id":"bc1UvbgH1D3Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702733213037,"user_tz":-60,"elapsed":15,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}},"outputId":"81969832-7ede-48a7-e7b4-2bc4c91f4d2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[57, 12, 18, 46, 79, 64, 28, 83, 67, 51]\n","[40, 38, 14, 50, 95, 54, 65, 16, 10, 68]\n","[70, 20, 41, 80, 17, 46, 31, 71, 90, 6]\n","[79, 60, 38, 65, 12, 29, 32, 45, 4, 97]\n","[37, 50, 88, 1, 38, 67, 62, 92, 16, 24]\n","[59, 28, 98, 25, 26, 83, 96, 31, 91, 84]\n","[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82]\n","[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81]\n","[1, 2, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 40, 41, 43, 44, 46, 47, 49, 50, 52, 53, 55, 56, 58, 59, 61, 62, 64, 65, 67, 68, 70, 71, 73, 74, 76, 77, 79, 80, 82, 83, 85, 86, 88, 89, 91, 92, 94, 95, 97, 98, 100, 101, 103, 104, 106, 107, 109, 110, 112, 113, 115, 116, 118, 119, 121, 122, 124, 125, 127, 128, 130, 131, 133, 134, 136, 137, 139, 140, 142, 143, 145, 146, 148, 149, 151, 152, 154, 155, 157, 158, 160, 161, 163, 164, 166, 167, 169, 170, 172, 173, 175, 176, 178, 179, 181, 182, 184, 185, 187, 188, 190, 191, 193, 194, 196, 197, 199, 200, 202, 203, 205, 206, 208]\n","[0, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 17, 18, 20, 21, 23, 24, 26, 27, 29, 30, 32, 33, 35, 36, 38, 39, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54, 56, 57, 59, 60, 62, 63, 65, 66, 68, 69, 71, 72, 74, 75, 77, 78, 80, 81, 83, 84, 86, 87, 89, 90, 92, 93, 95, 96, 98, 99, 101, 102, 104, 105, 107, 108, 110, 111, 113, 114, 116, 117, 119, 120, 122, 123, 125, 126, 128, 129, 131, 132, 134, 135, 137, 138, 140, 141, 143, 144, 146, 147, 149, 150, 152, 153, 155, 156, 158, 159, 161, 162, 164, 165, 167, 168, 170, 171, 173, 174, 176, 177, 179, 180, 182, 183, 185, 186, 188, 189, 191, 192, 194, 195, 197, 198, 200, 201, 203, 204, 206, 207]\n","[0, 1, 3, 4, 6, 7, 9, 10, 12, 13, 15, 16, 18, 19, 21, 22, 24, 25, 27, 28, 30, 31, 33, 34, 36, 37, 39, 40, 42, 43, 45, 46, 48, 49, 51, 52, 54, 55, 57, 58, 60, 61, 63, 64, 66, 67, 69, 70, 72, 73, 75, 76, 78, 79, 81, 82, 84, 85, 87, 88, 90, 91, 93, 94, 96, 97, 99, 100, 102, 103, 105, 106, 108, 109, 111, 112, 114, 115, 117, 118, 120, 121, 123, 124, 126, 127, 129, 130, 132, 133, 135, 136, 138, 139, 141, 142, 144, 145, 147, 148, 150, 151, 153, 154, 156, 157, 159, 160, 162, 163, 165, 166, 168, 169, 171, 172, 174, 175, 177, 178, 180, 181, 183, 184, 186, 187, 189, 190, 192, 193, 195, 196, 198, 199, 201, 202, 204, 205, 207, 208]\n","[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98]\n","[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99]\n","[1, 2, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 40, 41, 43, 44, 46, 47, 49, 50, 52, 53, 55, 56, 58, 59, 61, 62, 64, 65, 67, 68, 70, 71, 73, 74, 76, 77, 79, 80, 82, 83, 85, 86, 88, 89, 91, 92, 94, 95, 97, 98, 100, 101, 103, 104, 106, 107, 109, 110, 112, 113, 115, 116, 118, 119, 121, 122, 124, 125, 127, 128, 130, 131, 133, 134, 136, 137, 139, 140, 142, 143, 145, 146, 148, 149, 151, 152, 154, 155, 157, 158, 160, 161, 163, 164, 166, 167, 169, 170, 172, 173, 175, 176, 178, 179, 181, 182, 184, 185, 187, 188, 190, 191, 193, 194, 196, 197, 199, 200, 202, 203, 205, 206, 208, 209, 211, 212]\n","[0, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 17, 18, 20, 21, 23, 24, 26, 27, 29, 30, 32, 33, 35, 36, 38, 39, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54, 56, 57, 59, 60, 62, 63, 65, 66, 68, 69, 71, 72, 74, 75, 77, 78, 80, 81, 83, 84, 86, 87, 89, 90, 92, 93, 95, 96, 98, 99, 101, 102, 104, 105, 107, 108, 110, 111, 113, 114, 116, 117, 119, 120, 122, 123, 125, 126, 128, 129, 131, 132, 134, 135, 137, 138, 140, 141, 143, 144, 146, 147, 149, 150, 152, 153, 155, 156, 158, 159, 161, 162, 164, 165, 167, 168, 170, 171, 173, 174, 176, 177, 179, 180, 182, 183, 185, 186, 188, 189, 191, 192, 194, 195, 197, 198, 200, 201, 203, 204, 206, 207, 209, 210, 212]\n","[0, 1, 3, 4, 6, 7, 9, 10, 12, 13, 15, 16, 18, 19, 21, 22, 24, 25, 27, 28, 30, 31, 33, 34, 36, 37, 39, 40, 42, 43, 45, 46, 48, 49, 51, 52, 54, 55, 57, 58, 60, 61, 63, 64, 66, 67, 69, 70, 72, 73, 75, 76, 78, 79, 81, 82, 84, 85, 87, 88, 90, 91, 93, 94, 96, 97, 99, 100, 102, 103, 105, 106, 108, 109, 111, 112, 114, 115, 117, 118, 120, 121, 123, 124, 126, 127, 129, 130, 132, 133, 135, 136, 138, 139, 141, 142, 144, 145, 147, 148, 150, 151, 153, 154, 156, 157, 159, 160, 162, 163, 165, 166, 168, 169, 171, 172, 174, 175, 177, 178, 180, 181, 183, 184, 186, 187, 189, 190, 192, 193, 195, 196, 198, 199, 201, 202, 204, 205, 207, 208, 210, 211]\n","[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 112, 114]\n","[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99, 101, 103, 105, 107, 109, 111, 113]\n","[1, 2, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 40, 41, 43, 44, 46, 47, 49, 50, 52, 53, 55, 56, 58, 59, 61, 62, 64, 65, 67, 68, 70, 71, 73, 74, 76, 77, 79, 80, 82, 83, 85, 86, 88, 89, 91, 92, 94, 95, 97, 98, 100, 101, 103, 104, 106, 107, 109, 110, 112, 113, 115, 116, 118, 119, 121, 122, 124, 125, 127, 128, 130, 131, 133, 134, 136, 137, 139, 140, 142, 143, 145, 146, 148, 149, 151, 152, 154, 155, 157, 158, 160, 161, 163, 164, 166, 167, 169, 170, 172, 173, 175, 176, 178, 179, 181, 182, 184, 185, 187, 188, 190, 191, 193, 194, 196, 197, 199, 200, 202, 203, 205, 206, 208, 209, 211, 212, 214, 215, 217, 218]\n","[0, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 17, 18, 20, 21, 23, 24, 26, 27, 29, 30, 32, 33, 35, 36, 38, 39, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54, 56, 57, 59, 60, 62, 63, 65, 66, 68, 69, 71, 72, 74, 75, 77, 78, 80, 81, 83, 84, 86, 87, 89, 90, 92, 93, 95, 96, 98, 99, 101, 102, 104, 105, 107, 108, 110, 111, 113, 114, 116, 117, 119, 120, 122, 123, 125, 126, 128, 129, 131, 132, 134, 135, 137, 138, 140, 141, 143, 144, 146, 147, 149, 150, 152, 153, 155, 156, 158, 159, 161, 162, 164, 165, 167, 168, 170, 171, 173, 174, 176, 177, 179, 180, 182, 183, 185, 186, 188, 189, 191, 192, 194, 195, 197, 198, 200, 201, 203, 204, 206, 207, 209, 210, 212, 213, 215, 216, 218, 219]\n","[0, 1, 3, 4, 6, 7, 9, 10, 12, 13, 15, 16, 18, 19, 21, 22, 24, 25, 27, 28, 30, 31, 33, 34, 36, 37, 39, 40, 42, 43, 45, 46, 48, 49, 51, 52, 54, 55, 57, 58, 60, 61, 63, 64, 66, 67, 69, 70, 72, 73, 75, 76, 78, 79, 81, 82, 84, 85, 87, 88, 90, 91, 93, 94, 96, 97, 99, 100, 102, 103, 105, 106, 108, 109, 111, 112, 114, 115, 117, 118, 120, 121, 123, 124, 126, 127, 129, 130, 132, 133, 135, 136, 138, 139, 141, 142, 144, 145, 147, 148, 150, 151, 153, 154, 156, 157, 159, 160, 162, 163, 165, 166, 168, 169, 171, 172, 174, 175, 177, 178, 180, 181, 183, 184, 186, 187, 189, 190, 192, 193, 195, 196, 198, 199, 201, 202, 204, 205, 207, 208, 210, 211, 213, 214, 216, 217, 219]\n"]}],"source":["# Run at the end, but do not modify - we will use this to asses your output.\n","for c in CLASS_NAMES:\n","    s = pd.Series(results[c])\n","    print(s.sort_values(ascending=False)[:10].index.tolist())\n","    print(s.sort_values(ascending=True)[:10].index.tolist())\n","\n","def get_sorted_indices(loader):\n","    loader.dataset.return_only_indices = True\n","    indices = sorted([x.item() for x in loader])\n","    loader.dataset.return_only_indices = False\n","    return indices\n","\n","for c in CLASS_NAMES:\n","    print(get_sorted_indices(dataloaders[c][\"val_dataloader\"]))\n","    print(get_sorted_indices(dataloaders[c][\"test_dataloader\"]))\n","    for v in dataloaders[c][\"train_dataloaders\"]:\n","        print(get_sorted_indices(v))"]},{"cell_type":"markdown","metadata":{"id":"HgzSktT41D3Y"},"source":["# Task 2. Improving PADIM with Online Covariance Estimation\n","\n","This implementation of PADIM can be improved in numerous ways. In this exercise, you'll try to indicate its shortcomings and provide some means to mitigate them.\n","\n","#### 2.1. PADIM's training complexity (15%)\n","\n","- Identify the key operations contributing to the algorithm's training space complexity *in this implementation*. Don't focus on the backbone, as it is not the part of the algorithm (however, its output is).\n","- Shortly discuss the implications for scalability. You can support your claims by charts if needed.\n","\n","*Hint: this doesn't need to be super formal analysis - it's about fiding the \"worst\" parts of this implementation. You can support your claims with a chart and brief description (e.g. \"X dominates the complexity, as it's quadratic.\")*"]},{"cell_type":"markdown","metadata":{"id":"Dpp7vqEj1D3Y"},"source":["```Your answer to task 2.1 goes here```"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"KydMgYeM1D3Y","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1702733213037,"user_tz":-60,"elapsed":12,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}},"outputId":"ab5560c9-7516-466e-87a2-3698923cc656"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nKey operations contributing to the algorithm's training space complexity\\n- line with the following code: self.train_outputs[k].append(v.cpu().detach())\\n- this line contributes to storing embedding of entire embeddings dataset\\n- the memory space requirements grow linearly with size of the training dataset, size of embeddings\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}],"source":["# Your code goes here (if needed)\n","\"\"\"\n","Key operations contributing to the algorithm's training space complexity\n","- line with the following code: self.train_outputs[k].append(v.cpu().detach())\n","- this line contributes to storing embedding of entire embeddings dataset\n","- the memory space requirements grow linearly with size of the training dataset, size of embeddings\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"OXDqPKDy1D3Y"},"source":["#### 2.2 Online mean and covariance (35%)\n","Implement a PyTorch version of [online covariance matrix estimation](https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Online) in the training as an alternative to the current method in PADIM.\n","Calculate the mean in an online fashion as well.\n","Your implementation shall run on the selected `torch.device` (such as GPU).\n","No need to reimplement the testing routine to online in this exercise (although it'd be nice to have for Task 1), albeit small changes might be necessary (such as conversion from `torch.Tensor` to `np.ndarray`).\n","\n","Passing criteria:\n","```python\n","torch.allclose(padim_online.mean, torch.Tensor(padim_offline.mean).to(DEVICE), atol=0.01)\n","torch.allclose(padim_online.cov, torch.Tensor(padim_offline.cov).to(DEVICE), atol=0.01)\n","```\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"OA4gBcOd1D3Y","executionInfo":{"status":"ok","timestamp":1702733213038,"user_tz":-60,"elapsed":12,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[],"source":["class PADIMWithOnlineCovariance(PADIM):\n","\n","    ### TODO: Your code goes here\n","    def __init__(\n","            self,\n","            backbone: str,\n","            device: torch.device,\n","            save_path: Path,\n","            backbone_features_idx: List[int],\n","            class_names=[],\n","            plot_metrics=False,\n","            ) -> None:\n","        super().__init__(backbone, device, save_path, backbone_features_idx, class_names, plot_metrics)\n","\n","    def train(self, train_dataloader: DataLoader, C: int, H: int, W: int):\n","        \"\"\"C, H, W come from the size of embeddings: [B, C, H, W]\"\"\"\n","        self.train_outputs: Dict[str, List[torch.Tensor]] = {'layer1': [], 'layer2': [], 'layer3': []}\n","\n","        self.mean = torch.zeros((C, H * W)).numpy()\n","        self.cov = torch.zeros(C, C, H * W).numpy()\n","        I = np.identity(C)\n","        n = 0\n","\n","        for x, y, mask in tqdm(train_dataloader, desc='Feature extraction (train)'):\n","            # Run model prediction.\n","            with torch.no_grad():\n","                _ = self.model(x.to(DEVICE))\n","            # Get intermediate layer outputs.\n","            for k, v in self.outputs.items():\n","                self.train_outputs[k].append(v.cpu().detach())\n","\n","            embedding_vectors = concatenate_embeddings_from_all_layers({k: torch.cat(v, 0) for k, v in self.train_outputs.items()})\n","            embedding_vectors_subset = torch.index_select(embedding_vectors, 1, self.feature_subset_indices.cpu())\n","            embedding_vectors_subset = embedding_vectors_subset.view(x.size()[0], C, H * W)\n","\n","            # x_(n-1)\n","            prev_mean = self.mean.copy()\n","\n","            # x_n\n","            self.mean = self.mean + (torch.mean(embedding_vectors_subset, dim=0).numpy() - self.mean)/((n+1)*x.size()[0])\n","\n","            for i in range(H * W):\n","              self.cov[:,:,i] += (embedding_vectors_subset[:, :, i].numpy()-prev_mean[:, i]).T @ (embedding_vectors_subset[:,:,i].numpy()-self.mean[:, i])\n","            n += 1\n","\n","            # Reset hook outputs, buffor.\n","            for k, _ in self.outputs.items():\n","              self.train_outputs[k] = []\n","            self.outputs = {}\n","\n","        for i in range(H * W):\n","          self.cov[:,:,i] = self.cov[:,:,i]/(x.size()[0]*len(train_dataloader)) + 0.01*I\n","\n","        self.cov = torch.tensor(self.cov).to(self.device)\n","        self.mean = torch.tensor(self.mean).to(self.device)\n","\n","    ### END OF YOUR CODE"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"ZPjJjNbF1D3Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702733275076,"user_tz":-60,"elapsed":62050,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}},"outputId":"0540c4d4-f86a-48a2-ff25-9a1bf8303eb3"},"outputs":[{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 209/209 [00:10<00:00, 19.89it/s]\n","Covariance estimation: 100%|██████████| 3136/3136 [00:01<00:00, 2523.18it/s]\n","Feature extraction (train): 100%|██████████| 209/209 [00:42<00:00,  4.87it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":21}],"source":["# do not modify\n","seed_all(SEED)\n","class_name = 'bottle'\n","BATCH_SIZE = 1\n","RESIZE = 256 * 1\n","CROP_SIZE = 224 * 1\n","BACKBONE = \"resnet18\"\n","NUMBER_OF_BACKBONE_FEATURES = 30\n","MAX_NUMBER_OF_BACKBONE_FEATURES = 448\n","# DEVICE=\"cpu\"\n","\n","indices = sample_idx(NUMBER_OF_BACKBONE_FEATURES, MAX_NUMBER_OF_BACKBONE_FEATURES).to(DEVICE)\n","\n","run_timestamp = time.time()\n","SAVE_PATH = Path(f\"./results/{run_timestamp}/{class_name}\")\n","\n","train_dataset = MVTecDataset(DATA_PATH, class_name=class_name, is_train=True, resize=RESIZE, cropsize=CROP_SIZE)\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n","test_dataset = MVTecDataset(DATA_PATH, class_name=class_name, is_train=False, resize=RESIZE, cropsize=CROP_SIZE)\n","val_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n","\n","\n","padim_offline = PADIM(\n","    backbone=BACKBONE,\n","    device=DEVICE,\n","    backbone_features_idx=indices,\n","    save_path=SAVE_PATH,\n","    plot_metrics=True,\n",")\n","padim_offline.train(train_dataloader)\n","\n","padim_online = PADIMWithOnlineCovariance(\n","    backbone=BACKBONE,\n","    device=DEVICE,\n","    backbone_features_idx=indices,\n","    save_path=SAVE_PATH,\n","    plot_metrics=True,\n",")\n","padim_online.train(train_dataloader, NUMBER_OF_BACKBONE_FEATURES, int(CROP_SIZE/4), int(CROP_SIZE/4))\n","\n","torch.allclose(padim_online.mean, torch.Tensor(padim_offline.mean).to(DEVICE), atol=0.01) and torch.allclose(padim_online.cov, torch.Tensor(padim_offline.cov).to(DEVICE), atol=0.01)"]},{"cell_type":"markdown","metadata":{"id":"mCkYW4aH1D3Y"},"source":["#### 2.3 Performance experiments (10%)\n","If you completed task 2.2, design experiments to empirically compare space and memory performance of PADIM training with both traditional and online covariance matrix estimation. Write short conclusions."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"8CuL3Umf1D3Y","executionInfo":{"status":"ok","timestamp":1702733281804,"user_tz":-60,"elapsed":6752,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"outputs":[],"source":["# Your code goes here\n","!pip install memory-profiler -q\n","%load_ext memory_profiler"]},{"cell_type":"code","source":["padim_offline = PADIM(\n","    backbone=BACKBONE,\n","    device=DEVICE,\n","    backbone_features_idx=indices,\n","    save_path=SAVE_PATH,\n","    plot_metrics=True,\n",")\n","%memit padim_offline.train(train_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MWbNq3H0WbUr","executionInfo":{"status":"ok","timestamp":1702733311051,"user_tz":-60,"elapsed":29259,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}},"outputId":"491df10b-e7ef-4907-dcc4-91c87b5b0efc"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 209/209 [00:13<00:00, 15.28it/s]\n","Covariance estimation: 100%|██████████| 3136/3136 [00:02<00:00, 1285.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["peak memory: 5787.52 MiB, increment: 3440.51 MiB\n"]}]},{"cell_type":"code","source":["padim_online = PADIMWithOnlineCovariance(\n","    backbone=BACKBONE,\n","    device=DEVICE,\n","    backbone_features_idx=indices,\n","    save_path=SAVE_PATH,\n","    plot_metrics=True,\n",")\n","\n","%memit padim_online.train(train_dataloader, NUMBER_OF_BACKBONE_FEATURES, int(CROP_SIZE/4), int(CROP_SIZE/4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxxOe5eUWmZa","executionInfo":{"status":"ok","timestamp":1702733376075,"user_tz":-60,"elapsed":65030,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}},"outputId":"c8a996c5-60ca-4d7c-ba50-9ef23caaa67f"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["Feature extraction (train): 100%|██████████| 209/209 [01:02<00:00,  3.33it/s]"]},{"output_type":"stream","name":"stdout","text":["peak memory: 2348.21 MiB, increment: 0.10 MiB\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"WwXmZH011D3Z"},"source":["Online version of computing mean and covariance matrix requires 3000MiB less memory compared to the offline version.\n","\n","Peak memory usage of:\n","- offline version: 5787.52 MiB\n","- online version: 2348.21 MiB\n","\n","Therefore, my conclusion is that it substantially saves memory and is preferred over the offline version."]},{"cell_type":"code","source":[],"metadata":{"id":"qFyZIKHnYiM5","executionInfo":{"status":"ok","timestamp":1702733376075,"user_tz":-60,"elapsed":21,"user":{"displayName":"Paweł Narkiewicz","userId":"07792137702070356651"}}},"execution_count":24,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"colab":{"provenance":[{"file_id":"https://github.com/mim-uw/dnn-2023-24/blob/master/docs/hw2-visual_anomaly_detection-student.ipynb","timestamp":1701424944439}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}