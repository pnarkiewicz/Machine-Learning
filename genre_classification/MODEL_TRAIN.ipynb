{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder = 'Genre Classification Dataset'\n",
    "train_file = 'train_data.txt'\n",
    "test_file = 'test_data_solution.txt'\n",
    "\n",
    "def get_dataframe(file_name):\n",
    "    data = []\n",
    "\n",
    "    with open(os.path.join(folder, file_name)) as f:\n",
    "\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for idx, line in enumerate(lines):\n",
    "            \n",
    "            row = line.split(' ::: ')\n",
    "\n",
    "            try:\n",
    "                title = row[1].split(' (')[0]\n",
    "                year = row[1].split(' (')[1].split(')')[0]\n",
    "                genre = row[2]\n",
    "                description = row[3]\n",
    "                data.append([title, year, genre, description])\n",
    "            except Exception as exp:\n",
    "                print(exp)\n",
    "\n",
    "    return pd.DataFrame(data, columns=['title', 'year', 'genre', 'description'])\n",
    "\n",
    "df_train = get_dataframe(train_file)\n",
    "df_test = get_dataframe(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: 54214, test dataset: 54200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oscar et la dame rose</td>\n",
       "      <td>2009</td>\n",
       "      <td>drama</td>\n",
       "      <td>Listening in to a conversation between his doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cupid</td>\n",
       "      <td>1997</td>\n",
       "      <td>thriller</td>\n",
       "      <td>A brother and sister with a past incestuous re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Young, Wild and Wonderful</td>\n",
       "      <td>1980</td>\n",
       "      <td>adult</td>\n",
       "      <td>As the bus empties the students for their fiel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Secret Sin</td>\n",
       "      <td>1915</td>\n",
       "      <td>drama</td>\n",
       "      <td>To help their unemployed father make ends meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Unrecovered</td>\n",
       "      <td>2007</td>\n",
       "      <td>drama</td>\n",
       "      <td>The film's title refers not only to the un-rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  year     genre  \\\n",
       "0      Oscar et la dame rose  2009     drama   \n",
       "1                      Cupid  1997  thriller   \n",
       "2  Young, Wild and Wonderful  1980     adult   \n",
       "3             The Secret Sin  1915     drama   \n",
       "4            The Unrecovered  2007     drama   \n",
       "\n",
       "                                         description  \n",
       "0  Listening in to a conversation between his doc...  \n",
       "1  A brother and sister with a past incestuous re...  \n",
       "2  As the bus empties the students for their fiel...  \n",
       "3  To help their unemployed father make ends meet...  \n",
       "4  The film's title refers not only to the un-rec...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Size of training dataset: {len(df_train)}, test dataset: {len(df_test)}\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edgar's Lunch</td>\n",
       "      <td>1998</td>\n",
       "      <td>thriller</td>\n",
       "      <td>L.R. Brane loves his life - his car, his apart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La guerra de papá</td>\n",
       "      <td>1977</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Spain, March 1964: Quico is a very naughty chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Off the Beaten Track</td>\n",
       "      <td>2010</td>\n",
       "      <td>documentary</td>\n",
       "      <td>One year in the life of Albin and his family o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meu Amigo Hindu</td>\n",
       "      <td>2015</td>\n",
       "      <td>drama</td>\n",
       "      <td>His father has died, he hasn't spoken with his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Er nu zhai</td>\n",
       "      <td>1955</td>\n",
       "      <td>drama</td>\n",
       "      <td>Before he was known internationally as a marti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title  year        genre  \\\n",
       "0         Edgar's Lunch  1998     thriller   \n",
       "1     La guerra de papá  1977       comedy   \n",
       "2  Off the Beaten Track  2010  documentary   \n",
       "3       Meu Amigo Hindu  2015        drama   \n",
       "4            Er nu zhai  1955        drama   \n",
       "\n",
       "                                         description  \n",
       "0  L.R. Brane loves his life - his car, his apart...  \n",
       "1  Spain, March 1964: Quico is a very naughty chi...  \n",
       "2  One year in the life of Albin and his family o...  \n",
       "3  His father has died, he hasn't spoken with his...  \n",
       "4  Before he was known internationally as a marti...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = ['title', 'year', 'description']\n",
    "output_features = ['genre']\n",
    "\n",
    "X_train = df_train[input_features]\n",
    "y_train = df_train[output_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan for the model classifying genres based on title, year, description.\n",
    "\n",
    "1. Vectorize the data:\n",
    "    - genre2vec (straightforward)\n",
    "    - title2vec (complex)\n",
    "    - decription2vec (complex)\n",
    "2. Build 2 models and unittest them:\n",
    "    - ready-to-use model from a popular library\n",
    "    - implement LSTM with PyTorch\n",
    "    - implement a model using transformers ^^\n",
    "\n",
    "3. Train & debug models:\n",
    "    - ready-to-use: 0-small # of bugs expected\n",
    "    - LSTM: moderate # of bugs expected\n",
    "    - Transformers: high # of bugs expected\n",
    "\n",
    "4. Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_categories(dataframe, target):\n",
    "    return dataframe.join(pd.get_dummies(dataframe[target])).drop(columns=target)\n",
    "\n",
    "num_df_train = one_hot_encode_categories(df_train, 'genre')\n",
    "num_df_test = one_hot_encode_categories(df_test, 'genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>description</th>\n",
       "      <th>action</th>\n",
       "      <th>adult</th>\n",
       "      <th>adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>biography</th>\n",
       "      <th>comedy</th>\n",
       "      <th>crime</th>\n",
       "      <th>...</th>\n",
       "      <th>news</th>\n",
       "      <th>reality-tv</th>\n",
       "      <th>romance</th>\n",
       "      <th>sci-fi</th>\n",
       "      <th>short</th>\n",
       "      <th>sport</th>\n",
       "      <th>talk-show</th>\n",
       "      <th>thriller</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oscar et la dame rose</td>\n",
       "      <td>2009</td>\n",
       "      <td>Listening in to a conversation between his doc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cupid</td>\n",
       "      <td>1997</td>\n",
       "      <td>A brother and sister with a past incestuous re...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Young, Wild and Wonderful</td>\n",
       "      <td>1980</td>\n",
       "      <td>As the bus empties the students for their fiel...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Secret Sin</td>\n",
       "      <td>1915</td>\n",
       "      <td>To help their unemployed father make ends meet...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Unrecovered</td>\n",
       "      <td>2007</td>\n",
       "      <td>The film's title refers not only to the un-rec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  year  \\\n",
       "0      Oscar et la dame rose  2009   \n",
       "1                      Cupid  1997   \n",
       "2  Young, Wild and Wonderful  1980   \n",
       "3             The Secret Sin  1915   \n",
       "4            The Unrecovered  2007   \n",
       "\n",
       "                                         description  action  adult  \\\n",
       "0  Listening in to a conversation between his doc...       0      0   \n",
       "1  A brother and sister with a past incestuous re...       0      0   \n",
       "2  As the bus empties the students for their fiel...       0      1   \n",
       "3  To help their unemployed father make ends meet...       0      0   \n",
       "4  The film's title refers not only to the un-rec...       0      0   \n",
       "\n",
       "   adventure  animation  biography  comedy  crime  ...  news  reality-tv  \\\n",
       "0          0          0          0       0      0  ...     0           0   \n",
       "1          0          0          0       0      0  ...     0           0   \n",
       "2          0          0          0       0      0  ...     0           0   \n",
       "3          0          0          0       0      0  ...     0           0   \n",
       "4          0          0          0       0      0  ...     0           0   \n",
       "\n",
       "   romance  sci-fi  short  sport  talk-show  thriller  war  western  \n",
       "0        0       0      0      0          0         0    0        0  \n",
       "1        0       0      0      0          0         1    0        0  \n",
       "2        0       0      0      0          0         0    0        0  \n",
       "3        0       0      0      0          0         0    0        0  \n",
       "4        0       0      0      0          0         0    0        0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>description</th>\n",
       "      <th>action</th>\n",
       "      <th>adult</th>\n",
       "      <th>adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>biography</th>\n",
       "      <th>comedy</th>\n",
       "      <th>crime</th>\n",
       "      <th>...</th>\n",
       "      <th>news</th>\n",
       "      <th>reality-tv</th>\n",
       "      <th>romance</th>\n",
       "      <th>sci-fi</th>\n",
       "      <th>short</th>\n",
       "      <th>sport</th>\n",
       "      <th>talk-show</th>\n",
       "      <th>thriller</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edgar's Lunch</td>\n",
       "      <td>1998</td>\n",
       "      <td>L.R. Brane loves his life - his car, his apart...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La guerra de papá</td>\n",
       "      <td>1977</td>\n",
       "      <td>Spain, March 1964: Quico is a very naughty chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Off the Beaten Track</td>\n",
       "      <td>2010</td>\n",
       "      <td>One year in the life of Albin and his family o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meu Amigo Hindu</td>\n",
       "      <td>2015</td>\n",
       "      <td>His father has died, he hasn't spoken with his...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Er nu zhai</td>\n",
       "      <td>1955</td>\n",
       "      <td>Before he was known internationally as a marti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title  year  \\\n",
       "0         Edgar's Lunch  1998   \n",
       "1     La guerra de papá  1977   \n",
       "2  Off the Beaten Track  2010   \n",
       "3       Meu Amigo Hindu  2015   \n",
       "4            Er nu zhai  1955   \n",
       "\n",
       "                                         description  action  adult  \\\n",
       "0  L.R. Brane loves his life - his car, his apart...       0      0   \n",
       "1  Spain, March 1964: Quico is a very naughty chi...       0      0   \n",
       "2  One year in the life of Albin and his family o...       0      0   \n",
       "3  His father has died, he hasn't spoken with his...       0      0   \n",
       "4  Before he was known internationally as a marti...       0      0   \n",
       "\n",
       "   adventure  animation  biography  comedy  crime  ...  news  reality-tv  \\\n",
       "0          0          0          0       0      0  ...     0           0   \n",
       "1          0          0          0       1      0  ...     0           0   \n",
       "2          0          0          0       0      0  ...     0           0   \n",
       "3          0          0          0       0      0  ...     0           0   \n",
       "4          0          0          0       0      0  ...     0           0   \n",
       "\n",
       "   romance  sci-fi  short  sport  talk-show  thriller  war  western  \n",
       "0        0       0      0      0          0         1    0        0  \n",
       "1        0       0      0      0          0         0    0        0  \n",
       "2        0       0      0      0          0         0    0        0  \n",
       "3        0       0      0      0          0         0    0        0  \n",
       "4        0       0      0      0          0         0    0        0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# If not working python run python3 -m spacy download en_core_web_sm\n",
    "from nltk import sent_tokenize\n",
    "# If not working run nltk.download()\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize(description):\n",
    "    sentences = sent_tokenize(description)\n",
    "    description_lem = [word.lemma_ for sentence in sentences for word in nlp(sentence)]\n",
    "    return description_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_train_lem = [lemmatize(num_df_train.loc[i]['description']) for i in range(len(df_train[0:1000]))]\n",
    "description_test_lem = [lemmatize(num_df_train.loc[i]['description']) for i in range(len(df_test[0:1000]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 22:52:14,419 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t3>', 'datetime': '2023-01-05T22:52:14.419514', 'gensim': '4.3.0', 'python': '3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]', 'platform': 'macOS-11.7-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import common_texts\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "documents_train = [TaggedDocument(doc, [i]) for i, doc in enumerate(description_train_lem)]\n",
    "documents_test = [TaggedDocument(doc, [i]) for i, doc in enumerate(description_test_lem)]\n",
    "model = Doc2Vec(vector_size=50, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 22:52:14,461 : INFO : collecting all words and their counts\n",
      "2023-01-05 22:52:14,461 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-01-05 22:52:14,473 : INFO : collected 13359 word types and 1000 unique tags from a corpus of 1000 examples and 120217 words\n",
      "2023-01-05 22:52:14,473 : INFO : Creating a fresh vocabulary\n",
      "2023-01-05 22:52:14,484 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 6326 unique words (47.35% of original 13359, drops 7033)', 'datetime': '2023-01-05T22:52:14.484397', 'gensim': '4.3.0', 'python': '3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]', 'platform': 'macOS-11.7-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-01-05 22:52:14,484 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 113184 word corpus (94.15% of original 120217, drops 7033)', 'datetime': '2023-01-05T22:52:14.484739', 'gensim': '4.3.0', 'python': '3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]', 'platform': 'macOS-11.7-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-01-05 22:52:14,497 : INFO : deleting the raw counts dictionary of 13359 items\n",
      "2023-01-05 22:52:14,498 : INFO : sample=0.001 downsamples 39 most-common words\n",
      "2023-01-05 22:52:14,498 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 77280.52196717598 word corpus (68.3%% of prior 113184)', 'datetime': '2023-01-05T22:52:14.498223', 'gensim': '4.3.0', 'python': '3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]', 'platform': 'macOS-11.7-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-01-05 22:52:14,519 : INFO : estimated required memory for 6326 words and 50 dimensions: 6093400 bytes\n",
      "2023-01-05 22:52:14,519 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(documents_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'year' appeared 257 times in the training corpus.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word 'year' appeared {model.wv.get_vecattr('year', 'count')} times in the training corpus.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 22:52:14,590 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 6326 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-01-05T22:52:14.590354', 'gensim': '4.3.0', 'python': '3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]', 'platform': 'macOS-11.7-arm64-arm-64bit', 'event': 'train'}\n",
      "2023-01-05 22:52:14,639 : INFO : EPOCH 0: training on 120217 raw words (78378 effective words) took 0.0s, 1635059 effective words/s\n",
      "2023-01-05 22:52:14,688 : INFO : EPOCH 1: training on 120217 raw words (78181 effective words) took 0.0s, 1651847 effective words/s\n",
      "2023-01-05 22:52:14,739 : INFO : EPOCH 2: training on 120217 raw words (78091 effective words) took 0.0s, 1571120 effective words/s\n",
      "2023-01-05 22:52:14,877 : INFO : EPOCH 3: training on 120217 raw words (78129 effective words) took 0.1s, 594106 effective words/s\n",
      "2023-01-05 22:52:14,922 : INFO : EPOCH 4: training on 120217 raw words (78248 effective words) took 0.0s, 1806143 effective words/s\n",
      "2023-01-05 22:52:14,971 : INFO : EPOCH 5: training on 120217 raw words (78444 effective words) took 0.0s, 1656528 effective words/s\n",
      "2023-01-05 22:52:15,020 : INFO : EPOCH 6: training on 120217 raw words (78252 effective words) took 0.0s, 1636140 effective words/s\n",
      "2023-01-05 22:52:15,069 : INFO : EPOCH 7: training on 120217 raw words (78270 effective words) took 0.0s, 1638712 effective words/s\n",
      "2023-01-05 22:52:15,118 : INFO : EPOCH 8: training on 120217 raw words (78185 effective words) took 0.0s, 1633720 effective words/s\n",
      "2023-01-05 22:52:15,167 : INFO : EPOCH 9: training on 120217 raw words (78176 effective words) took 0.0s, 1625955 effective words/s\n",
      "2023-01-05 22:52:15,215 : INFO : EPOCH 10: training on 120217 raw words (78149 effective words) took 0.0s, 1671464 effective words/s\n",
      "2023-01-05 22:52:15,263 : INFO : EPOCH 11: training on 120217 raw words (78226 effective words) took 0.0s, 1690153 effective words/s\n",
      "2023-01-05 22:52:15,310 : INFO : EPOCH 12: training on 120217 raw words (78271 effective words) took 0.0s, 1684707 effective words/s\n",
      "2023-01-05 22:52:15,357 : INFO : EPOCH 13: training on 120217 raw words (78329 effective words) took 0.0s, 1705206 effective words/s\n",
      "2023-01-05 22:52:15,405 : INFO : EPOCH 14: training on 120217 raw words (78512 effective words) took 0.0s, 1691226 effective words/s\n",
      "2023-01-05 22:52:15,454 : INFO : EPOCH 15: training on 120217 raw words (78103 effective words) took 0.0s, 1628245 effective words/s\n",
      "2023-01-05 22:52:15,502 : INFO : EPOCH 16: training on 120217 raw words (78309 effective words) took 0.0s, 1669719 effective words/s\n",
      "2023-01-05 22:52:15,550 : INFO : EPOCH 17: training on 120217 raw words (78494 effective words) took 0.0s, 1679790 effective words/s\n",
      "2023-01-05 22:52:15,599 : INFO : EPOCH 18: training on 120217 raw words (78299 effective words) took 0.0s, 1635947 effective words/s\n",
      "2023-01-05 22:52:15,647 : INFO : EPOCH 19: training on 120217 raw words (78242 effective words) took 0.0s, 1644731 effective words/s\n",
      "2023-01-05 22:52:15,696 : INFO : EPOCH 20: training on 120217 raw words (78234 effective words) took 0.0s, 1649781 effective words/s\n",
      "2023-01-05 22:52:15,744 : INFO : EPOCH 21: training on 120217 raw words (78141 effective words) took 0.0s, 1666057 effective words/s\n",
      "2023-01-05 22:52:15,791 : INFO : EPOCH 22: training on 120217 raw words (78244 effective words) took 0.0s, 1673182 effective words/s\n",
      "2023-01-05 22:52:15,840 : INFO : EPOCH 23: training on 120217 raw words (78195 effective words) took 0.0s, 1635702 effective words/s\n",
      "2023-01-05 22:52:15,888 : INFO : EPOCH 24: training on 120217 raw words (78203 effective words) took 0.0s, 1657117 effective words/s\n",
      "2023-01-05 22:52:15,936 : INFO : EPOCH 25: training on 120217 raw words (78285 effective words) took 0.0s, 1670225 effective words/s\n",
      "2023-01-05 22:52:15,984 : INFO : EPOCH 26: training on 120217 raw words (78330 effective words) took 0.0s, 1654045 effective words/s\n",
      "2023-01-05 22:52:16,033 : INFO : EPOCH 27: training on 120217 raw words (78236 effective words) took 0.0s, 1641025 effective words/s\n",
      "2023-01-05 22:52:16,082 : INFO : EPOCH 28: training on 120217 raw words (78140 effective words) took 0.0s, 1646857 effective words/s\n",
      "2023-01-05 22:52:16,130 : INFO : EPOCH 29: training on 120217 raw words (78227 effective words) took 0.0s, 1669919 effective words/s\n",
      "2023-01-05 22:52:16,177 : INFO : EPOCH 30: training on 120217 raw words (78095 effective words) took 0.0s, 1683210 effective words/s\n",
      "2023-01-05 22:52:16,225 : INFO : EPOCH 31: training on 120217 raw words (78387 effective words) took 0.0s, 1663024 effective words/s\n",
      "2023-01-05 22:52:16,273 : INFO : EPOCH 32: training on 120217 raw words (78213 effective words) took 0.0s, 1666996 effective words/s\n",
      "2023-01-05 22:52:16,321 : INFO : EPOCH 33: training on 120217 raw words (78227 effective words) took 0.0s, 1681545 effective words/s\n",
      "2023-01-05 22:52:16,369 : INFO : EPOCH 34: training on 120217 raw words (78213 effective words) took 0.0s, 1671653 effective words/s\n",
      "2023-01-05 22:52:16,417 : INFO : EPOCH 35: training on 120217 raw words (78159 effective words) took 0.0s, 1654204 effective words/s\n",
      "2023-01-05 22:52:16,465 : INFO : EPOCH 36: training on 120217 raw words (78362 effective words) took 0.0s, 1682387 effective words/s\n",
      "2023-01-05 22:52:16,512 : INFO : EPOCH 37: training on 120217 raw words (78319 effective words) took 0.0s, 1703420 effective words/s\n",
      "2023-01-05 22:52:16,560 : INFO : EPOCH 38: training on 120217 raw words (78152 effective words) took 0.0s, 1657068 effective words/s\n",
      "2023-01-05 22:52:16,609 : INFO : EPOCH 39: training on 120217 raw words (78256 effective words) took 0.0s, 1667788 effective words/s\n",
      "2023-01-05 22:52:16,609 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4808680 raw words (3129906 effective words) took 2.0s, 1550361 effective words/s', 'datetime': '2023-01-05T22:52:16.609606', 'gensim': '4.3.0', 'python': '3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]', 'platform': 'macOS-11.7-arm64-arm-64bit', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model.train(documents_train, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03039514 -0.09620716 -0.36460468 -0.1251611  -0.15589844 -0.21638525\n",
      " -0.06199964  0.2630613   0.08590225 -0.08173687  0.01497169  0.40753338\n",
      "  0.05708568 -0.08460815 -0.36787924  0.11084662  0.27798635 -0.19433294\n",
      "  0.29197362 -0.10215756  0.47113967  0.22969201  0.46374136 -0.33741337\n",
      "  0.2220612  -0.1525057   0.29358184 -0.20131418 -0.08077633 -0.19337368\n",
      "  0.19067386  0.2094886  -0.42541397  0.22059736 -0.5109805   0.18710195\n",
      "  0.05757324 -0.43431732 -0.56124634 -0.38296095 -0.0530347   0.04964468\n",
      "  0.28948095  0.3143342   0.5137067   0.16092952 -0.07840962 -0.3617826\n",
      " -0.08346063  0.03003765]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', '.', 'fires', 'also', 'you', 'need', 'to', 'learn', '.'])\n",
    "print(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(documents_train)):\n",
    "    inferred_vector = model.infer_vector(documents_train[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1000})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (334): «in 1976 , William Wyler become the fourth recipient of the American Film Institute 's Lifetime Achievement Award , follow John Ford , James Cagney and Orson Welles . the winner of three Best Director Academy Awards ( and a record twelve nomination ) , Wyler have direct more oscar - win performance than any other director : Walter Brennan ( twice ) , Bette Davis , Fay Bainter , Greer Garson , Teresa Wright , Fredric March , Harold Russell , Olivia de Havilland , Audrey Hepburn , Burl Ives , Charlton Heston , Hugh Griffith and Barbra Streisand . among the film luminary who pay tribute to Wyler be Audrey Hepburn , Gregory Peck , Myrna Loy , Henry Fonda , James Stewart , Barbra Streisand , Charlton Heston , Eddie Albert , Merle Oberon , Walter Pidgeon , Greer Garson and Harold Russell . Film clip include : \" the good year of our life , \" \" Roman Holiday , \" \" Ben - Hur , \" \" Mrs. Miniver , \" \" Funny Girl , \" \" Wuthering Heights , \" and \" the Heiress . \" conspicously absent from the tribute be Bette Davis ( \" Jezebel , \" \" the Letter , \" \" the little fox \" ) , perhaps Wyler 's great success .»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t3>:\n",
      "\n",
      "MOST (334, 0.9754997491836548): «in 1976 , William Wyler become the fourth recipient of the American Film Institute 's Lifetime Achievement Award , follow John Ford , James Cagney and Orson Welles . the winner of three Best Director Academy Awards ( and a record twelve nomination ) , Wyler have direct more oscar - win performance than any other director : Walter Brennan ( twice ) , Bette Davis , Fay Bainter , Greer Garson , Teresa Wright , Fredric March , Harold Russell , Olivia de Havilland , Audrey Hepburn , Burl Ives , Charlton Heston , Hugh Griffith and Barbra Streisand . among the film luminary who pay tribute to Wyler be Audrey Hepburn , Gregory Peck , Myrna Loy , Henry Fonda , James Stewart , Barbra Streisand , Charlton Heston , Eddie Albert , Merle Oberon , Walter Pidgeon , Greer Garson and Harold Russell . Film clip include : \" the good year of our life , \" \" Roman Holiday , \" \" Ben - Hur , \" \" Mrs. Miniver , \" \" Funny Girl , \" \" Wuthering Heights , \" and \" the Heiress . \" conspicously absent from the tribute be Bette Davis ( \" Jezebel , \" \" the Letter , \" \" the little fox \" ) , perhaps Wyler 's great success .»\n",
      "\n",
      "MOST2 (972, 0.7873572707176208): «Roma , anni ' 50 . dopo la Seconda Guerra Mondiale c'č penuria di alloggi . Ciň ha costretto la coabitazione , in uno stesso appartamento , di due nuclei familiari : una famiglia di profughi istriani e la famiglia di Peppino Armentano , callista , che comprende , anche la moglie , il suocero , due figlie e due figli . Quando le condizioni cambiano , Peppino decide di cercarsi un altro alloggio . Conosce Pino Calamari , che gli offre un appartamento spazioso e comodo e ad un prezzo irrisorio . peppino accetta l'offerta e si trasferisce con la famiglia nella nuova abitazione . l'ingresso dei nuovi inquilini provoca le risate di scherno dei vicini : l'appartamento era stato in precedenza una \" casa chiusa \" , oggi abolite grazie alla Legge Merlin . da questa situazione nascono numerosi equivoci , al punto da far pensare alla moglie di Peppino di lasciare l'appartamento . alla fine , perň , tutto si aggiusta per il meglio .»\n",
      "\n",
      "MEDIAN (725, 0.2957228422164917): «due to a sudden shift in the global climate , the world as we once know it have suffer catastrophic circumstance . the survivor have seek refuge in massive underground bunker where they live and thrive . that be , until Jackson Bean wake up from his dream .»\n",
      "\n",
      "LEAST (661, -0.24899689853191376): «the action take place in a bulgarian village , inhabit mostly by woman . Bereft of mean for live , their husband work in the town and be rare to show up . the woman work , have fun and enjoy a wonderful sense of solidarity . the woman 's everyday life be not easy : they work in the field , keep the house go , they be lonely . they help each other , at time , quarrel , and dream along with the funny event that occur . however , it turn out that each of these woman have own personal drama . Old Yordana , whose son be professor , have choose to await death alone . Ganeta 's husband want she to seduce an auditor in the hope that the embezzlement for which he be eventually imprison will not be detect . some time later she commit adultery against her will and suffer under the burden of her ' sin ' , which gets know in the village . Stipana , for her part , find her only solace in the brandy she distil at home . and Zhela , just like Yordana , face a lonely old age . Tana despise her husband for be unable to arrange their departure to the nearby city . this be what their life be like . they , however , stand up to hardship and hope spring eternal . this be a film about the rupture of family tie and the character ' deep - root love for their simple life close to nature .»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(documents_test) - 1)\n",
    "inferred_vector = model.infer_vector(list(documents_test[doc_id])[0])\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(list(documents_test[doc_id])[0])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MOST2', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(documents_train[sims[index][0]].words)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Build 2 models and unittest them:\n",
    "    - ready-to-use model from a popular library\n",
    "    - implement LSTM with PyTorch\n",
    "    - implement a model using transformers ^^\n",
    "\n",
    "3. Train & debug models:\n",
    "    - ready-to-use: 0-small # of bugs expected\n",
    "    - LSTM: moderate # of bugs expected\n",
    "    - Transformers: high # of bugs expected\n",
    "\n",
    "4. Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('deepsenseai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb7720597c668dab0846ca2cc640fd001ce837d43a9c71f81a265cbfaca086e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
